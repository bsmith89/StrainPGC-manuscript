{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "# %autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "os.path.realpath(os.path.curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sfacts as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "from lib.pandas_util import idxwhere\n",
    "import matplotlib as mpl\n",
    "import lib.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d__Bacteria;p__Bacteroidota;c__Bacteroidia;o__Bacteroidales;f__Bacteroidaceae;g__Bacteroides_B;s__Bacteroides_B dorei\n",
    "species_id = '102478'  # '100035'  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgen = pd.read_table('meta/ucfmt/mgen.tsv', index_col=['mgen_id'])\n",
    "sample = pd.read_table('meta/ucfmt/sample.tsv', index_col=['sample_id'])\n",
    "subject = pd.read_table('meta/ucfmt/subject.tsv', index_col=['subject_id'])\n",
    "\n",
    "assert mgen.sample_id.isin(sample.index).all()\n",
    "assert sample.subject_id.isin(subject.index).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_species_depth = (\n",
    "    pd.read_table('data/ucfmt.a.r.proc.gtpro.species_depth.tsv')\n",
    "    .assign(species_id=lambda x: x.species_id.astype(str))\n",
    "    .set_index(['sample', 'species_id'])\n",
    "    .squeeze()\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "pseudo = 1e-3\n",
    "plt.hist(np.log10(_species_depth[species_id] + pseudo), bins=50)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = mgen.join(sample, on='sample_id')[lambda x: x.subject_id.str.startswith('S0')].assign(\n",
    "    total_species_depth=_species_depth.sum(1)\n",
    ")\n",
    "duplicated_subject_mgen_id_list = idxwhere(m.duplicated(subset=['subject_id', 'sample_type_specific'], keep=False))\n",
    "m.loc[duplicated_subject_mgen_id_list].sort_values(['subject_id', 'sample_type_specific'])[['subject_id', 'sample_type_specific', 'total_species_depth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_mgen_id_list = ['SS01008', 'SS01093c', 'SS01013', 'SS01117', 'SS01120', 'SS01126', 'SS01185']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# fit = sf.World.load(f'data/sp-{species_id}.ucfmt.a.r.proc.gtpro.filt-poly05-cvrg05.ss-g10000-block0-seed0.fit-sfacts11-s75-seed0.world.nc').collapse_similar_strains(thresh=0.05).drop_low_abundance_strains(thresh=0.01)\n",
    "_fit = sf.World.load(f'data_temp/sp-{species_id}.ucfmt.a.r.proc.gtpro.filt-poly05-cvrg05.ss-g10000-block0-seed0.fit-sfacts11-s75-seed0.world.nc')\n",
    "# _fit = _fit.collapse_similar_strains(thresh=0.1).drop_low_abundance_strains(thresh=0.05)\n",
    "_fit = _fit.collapse_similar_strains(thresh=0.01).drop_low_abundance_strains(thresh=0.05)\n",
    "\n",
    "\n",
    "# fit_rename = fit.data.copy()'\n",
    "# fit_rename['sample'] = fit.data.sample.to_series().map(meta['fullname']).to_list()\n",
    "# fit = sf.data.World(fit_rename)\n",
    "\n",
    "position_ss = _fit.random_sample(position=min(1000, len(_fit.position))).position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.evaluation.metagenotype_error2(_fit, discretized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.plot.plot_community(\n",
    "    _fit.sel(position=position_ss),\n",
    "    col_linkage_func=lambda w: w.metagenotype.linkage(),\n",
    "    row_linkage_func=lambda w: w.genotype.linkage(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgen_id = 'DS0097_035'\n",
    "sf.plot.plot_metagenotype_frequency_spectrum(_fit, mgen_id, bins=51)\n",
    "_fit.community.data.sel(sample=mgen_id).to_series().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgen_id = 'DS0097_025'\n",
    "sf.plot.plot_metagenotype_frequency_spectrum(_fit, mgen_id, bins=51)\n",
    "_fit.community.data.sel(sample=mgen_id).to_series().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgen_id = 'DS0044_003'\n",
    "sf.plot.plot_metagenotype_frequency_spectrum(_fit, mgen_id, bins=51)\n",
    "_fit.community.data.sel(sample=mgen_id).to_series().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgen_id = 'DS0097_013'\n",
    "sf.plot.plot_metagenotype_frequency_spectrum(_fit, mgen_id, bins=51)\n",
    "_fit.community.data.sel(sample=mgen_id).to_series().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgen_id = 'DS0097_034'\n",
    "sf.plot.plot_metagenotype_frequency_spectrum(_fit, mgen_id, bins=51)\n",
    "_fit.community.data.sel(sample=mgen_id).to_series().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgen_id = 'SS01200'\n",
    "sf.plot.plot_metagenotype_frequency_spectrum(_fit, mgen_id, bins=51)\n",
    "_fit.community.data.sel(sample=mgen_id).to_series().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.plot.plot_metagenotype(\n",
    "    _fit.sel(position=position_ss),\n",
    "    col_linkage_func=lambda w: w.metagenotype.linkage(),\n",
    "    scaley=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_fit.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.plot.plot_genotype(\n",
    "    _fit.sel(position=position_ss),\n",
    "    col_linkage_func=lambda w: w.metagenotype.linkage('position'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_meta_all = mgen.drop(drop_mgen_id_list).join(sample, on='sample_id').join(subject, on='subject_id').assign(\n",
    "    total_species_depth=_species_depth.sum(1),\n",
    "    species_depth=_species_depth[species_id],\n",
    "    is_fit=lambda x: x.index.to_series().isin(_fit.sample.to_series()),\n",
    ")\n",
    "_meta_all['fullname'] = (\n",
    "    _meta_all\n",
    "    .groupby(['subject_id', 'sample_type_specific'])\n",
    "    .apply(lambda df: df.assign(_i=range(len(df.index))))\n",
    "    .apply(lambda x: x.subject_id + '.' + x.sample_type_specific + '.' + str(x._i), axis=1)\n",
    ")\n",
    "_meta_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = _fit.data.sel(sample=idxwhere(_meta_all.is_fit))\n",
    "fit['sample'] = _meta_all.loc[idxwhere(_meta_all.is_fit)].fullname.values\n",
    "fit = sf.World(fit)\n",
    "\n",
    "meta_all = _meta_all.set_index('fullname')\n",
    "species_depth = _species_depth.rename(_meta_all.fullname)\n",
    "\n",
    "meta_all, species_depth = lib.plot.align_indexes(meta_all, species_depth)\n",
    "\n",
    "pseudo = 1e-3\n",
    "plt.hist(np.log10(species_depth[species_id] + pseudo), bins=50)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_rabund = species_depth.divide(species_depth.sum(1), axis=0)\n",
    "\n",
    "pseudo = 1e-6\n",
    "plt.hist(np.log10(species_rabund[species_id] + pseudo), bins=50)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.plot.plot_community(\n",
    "    fit.sel(position=position_ss),\n",
    "    col_linkage_func=lambda w: w.metagenotype.linkage(),\n",
    "    row_linkage_func=lambda w: w.genotype.linkage(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.plot.plot_metagenotype(\n",
    "    fit.sel(position=position_ss),\n",
    "    col_linkage_func=lambda w: w.metagenotype.linkage(),\n",
    "    scaley=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.plot.plot_genotype(\n",
    "    fit.sel(position=position_ss),\n",
    "    col_linkage_func=lambda w: w.metagenotype.linkage('position'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_type_specific_order = [\n",
    "    'baseline',\n",
    "    'pre_maintenance_1', 'pre_maintenance_2', 'pre_maintenance_3',\n",
    "    'pre_maintenance_4', 'pre_maintenance_5', 'pre_maintenance_6',\n",
    "    'followup_1', 'followup_2', 'followup_3',\n",
    "]\n",
    "sample_type_specific_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = meta_all.drop(idxwhere(meta_all.recipient == 0))\n",
    "d = m.set_index(['subject_id', 'sample_type_specific']).total_species_depth.unstack()[sample_type_specific_order]\n",
    "\n",
    "sns.heatmap(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total metagenome depth\n",
    "\n",
    "m = meta_all.drop(idxwhere(meta_all.recipient == 0))\n",
    "d = m.set_index(['subject_id', 'sample_type_specific']).total_species_depth.unstack()[sample_type_specific_order]\n",
    "is_fit_annot = m.set_index(['subject_id', 'sample_type_specific']).is_fit.unstack(fill_value=False)[sample_type_specific_order]\n",
    "\n",
    "sns.heatmap(d, annot=is_fit_annot, norm=mpl.colors.SymLogNorm(linthresh=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species depth\n",
    "\n",
    "m = meta_all.drop(idxwhere(meta_all.recipient == 0))\n",
    "d = m.set_index(['subject_id', 'sample_type_specific']).species_depth.unstack()[sample_type_specific_order]\n",
    "is_fit_annot = m.set_index(['subject_id', 'sample_type_specific']).is_fit.unstack(fill_value=False)[sample_type_specific_order]\n",
    "\n",
    "sns.heatmap(d, annot=is_fit_annot, norm=mpl.colors.SymLogNorm(linthresh=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log10(species_rabund[species_id] + 1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_depth = ((fit.community.data * species_depth[species_id].to_xarray())).to_pandas().reindex(idxwhere(meta_all.species_depth.notna()), fill_value=0)\n",
    "strain_rabund = ((fit.community.data * species_rabund[species_id].to_xarray())).to_pandas().reindex(idxwhere(meta_all.species_depth.notna()), fill_value=0)\n",
    "strain_rabund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(strain_rabund, figsize=(10, 15), yticklabels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list = [\"#91322d\", \"#62ecb6\", \"#ed0e1c\", \"#c2dcb8\", \"#cf115d\", \"#399283\", \"#f37d21\", \"#5310f0\", \"#f1c039\", \"#5d4030\", \"#f8cac2\", \"#74aff3\", \"#aa7b1b\", \"#35618f\", \"#9dd84e\", \"#6538ac\", \"#5c922f\", \"#e033d3\", \"#61f22d\", \"#dd8eeb\", \"#0b5313\", \"#fd8992\", \"#20d8fd\"]\n",
    "strain_order = strain_rabund.mean().sort_values(ascending=False).index\n",
    "strain_palette = lib.plot.construct_ordered_palette_from_list(strain_order, colors=color_list)\n",
    "\n",
    "thresh = 1e-4\n",
    "sample_type_x = pd.Series(dict(\n",
    "    donor=-1,\n",
    "    baseline=0,\n",
    "    pre_maintenance_1=1,\n",
    "    pre_maintenance_2=2,\n",
    "    pre_maintenance_3=3,\n",
    "    pre_maintenance_4=4,\n",
    "    pre_maintenance_5=5,\n",
    "    pre_maintenance_6=6,\n",
    "    followup_1=7,\n",
    "    followup_2=8,\n",
    "    followup_3=9,\n",
    "))\n",
    "\n",
    "\n",
    "subject_order = ['S0001', 'S0027', 'S0053', 'S0059', 'S0063']\n",
    "ncols = 5\n",
    "nrows = int(np.ceil(len(subject_order) / ncols))\n",
    "\n",
    "fig, axs = plt.subplots(nrows, ncols, sharex=True, sharey=True, figsize=(3 * ncols, 2.5 * nrows))\n",
    "axs = np.reshape(axs, (nrows, ncols))\n",
    "\n",
    "for subject_id, ax in zip(subject_order, axs.flatten()):\n",
    "    donor_id = subject.loc[subject_id].donor_subject_id\n",
    "\n",
    "    donor_sample_list = idxwhere(meta_all.subject_id == donor_id)\n",
    "    donor_mean_sample_rabund = strain_rabund.loc[donor_sample_list].mean()\n",
    "    donor_strain_list = idxwhere((donor_mean_sample_rabund > thresh))\n",
    "\n",
    "    try:\n",
    "        baseline_sample = meta_all[lambda x: (x.sample_type_specific == 'baseline') & (x.subject_id == subject_id)].index[0]\n",
    "    except IndexError:\n",
    "        baseline_strain_list = []\n",
    "    else:\n",
    "        baseline_sample_rabund = strain_rabund.loc[baseline_sample]\n",
    "        baseline_strain_list = idxwhere((baseline_sample_rabund > thresh))\n",
    "\n",
    "    subject_sample_list = idxwhere(meta_all.subject_id == subject_id)\n",
    "    common_strains = idxwhere((strain_rabund.loc[subject_sample_list + donor_sample_list] > thresh * 10).sum() >= 3)\n",
    "    focal_strains = list(set(donor_strain_list) | set(baseline_strain_list) | set(common_strains))\n",
    "\n",
    "    d0 = strain_rabund.loc[subject_sample_list].join(meta_all[['sample_type_specific']]).set_index('sample_type_specific')\n",
    "    d1 = pd.concat([d0, donor_mean_sample_rabund.to_frame('donor').T])\n",
    "    d2 = d1[focal_strains].assign(other=d1.sum(1) - d1[focal_strains].sum(1)).assign(x=sample_type_x).sort_values('x')\n",
    "    d3 = d2.drop('donor')\n",
    "\n",
    "    for strain in focal_strains + ['other']:\n",
    "        ax.plot(d3['x'], d3[strain], c=strain_palette[strain], marker='o', alpha=0.7, lw=2)\n",
    "        if donor_sample_list:\n",
    "            ax.scatter(d2.loc['donor', 'x'], d2.loc['donor', strain], c=strain_palette[strain], marker='o', alpha=0.7, s=70)\n",
    "    ax.set_title((subject_id, donor_id))\n",
    "\n",
    "ax.set_yscale('symlog', linthresh=thresh)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "for ax in axs[-1]:\n",
    "    ax.set_xticks(sample_type_x.values)\n",
    "    ax.set_xticklabels(sample_type_x.index, rotation=45, ha='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list = [\"#91322d\", \"#62ecb6\", \"#ed0e1c\", \"#c2dcb8\", \"#cf115d\", \"#399283\", \"#f37d21\", \"#5310f0\", \"#f1c039\", \"#5d4030\", \"#f8cac2\", \"#74aff3\", \"#aa7b1b\", \"#35618f\", \"#9dd84e\", \"#6538ac\", \"#5c922f\", \"#e033d3\", \"#61f22d\", \"#dd8eeb\", \"#0b5313\", \"#fd8992\", \"#20d8fd\"]\n",
    "strain_order = strain_rabund.mean().sort_values(ascending=False).index\n",
    "strain_palette = lib.plot.construct_ordered_palette_from_list(strain_order, colors=color_list)\n",
    "\n",
    "for strain_id in strain_palette:\n",
    "    plt.scatter([], [], marker='o', c=strain_palette[strain_id], label=strain_id)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list = [\"#91322d\", \"#62ecb6\", \"#ed0e1c\", \"#c2dcb8\", \"#cf115d\", \"#399283\", \"#f37d21\", \"#5310f0\", \"#f1c039\", \"#5d4030\", \"#f8cac2\", \"#74aff3\", \"#aa7b1b\", \"#35618f\", \"#9dd84e\", \"#6538ac\", \"#5c922f\", \"#e033d3\", \"#61f22d\", \"#dd8eeb\", \"#0b5313\", \"#fd8992\", \"#20d8fd\"]\n",
    "strain_order = strain_rabund.mean().sort_values(ascending=False).index\n",
    "strain_palette = lib.plot.construct_ordered_palette_from_list(strain_order, colors=color_list, other='lightgrey')\n",
    "\n",
    "thresh = 1e-4\n",
    "sample_type_x = pd.Series(dict(\n",
    "    donor=-2,\n",
    "    baseline=0,\n",
    "    pre_maintenance_1=1,\n",
    "    pre_maintenance_2=2,\n",
    "    pre_maintenance_3=3,\n",
    "    pre_maintenance_4=4,\n",
    "    pre_maintenance_5=5,\n",
    "    pre_maintenance_6=6,\n",
    "    followup_1=7,\n",
    "    followup_2=8,\n",
    "    followup_3=9,\n",
    "))\n",
    "\n",
    "\n",
    "all_subjects = idxwhere(meta_all[meta_all.recipient.astype(bool)].subject_id.value_counts() > 2)\n",
    "focal_subjects = ['S0001', 'S0027', 'S0053', 'S0059', 'S0063']\n",
    "subject_order = focal_subjects + [s for s in all_subjects if s not in focal_subjects]\n",
    "\n",
    "ncols = 5\n",
    "nrows = int(np.ceil(len(subject_order) / ncols))\n",
    "\n",
    "fig, axs = plt.subplots(nrows, ncols, sharex=True, sharey=True, figsize=(3 * ncols, 2.5 * nrows))\n",
    "axs = np.reshape(axs, (nrows, ncols))\n",
    "\n",
    "for subject_id, ax in zip(subject_order, axs.flatten()):\n",
    "    donor_id = subject.loc[subject_id].donor_subject_id\n",
    "\n",
    "    donor_sample_list = idxwhere(meta_all.subject_id == donor_id)\n",
    "    donor_mean_sample_rabund = strain_rabund.loc[donor_sample_list].mean()\n",
    "    donor_strain_list = idxwhere((donor_mean_sample_rabund > thresh))\n",
    "\n",
    "    try:\n",
    "        baseline_sample = meta_all[lambda x: (x.sample_type_specific == 'baseline') & (x.subject_id == subject_id)].index[0]\n",
    "    except IndexError:\n",
    "        baseline_strain_list = []\n",
    "    else:\n",
    "        baseline_sample_rabund = strain_rabund.loc[baseline_sample]\n",
    "        baseline_strain_list = idxwhere((baseline_sample_rabund > thresh))\n",
    "\n",
    "    subject_sample_list = idxwhere(meta_all.subject_id == subject_id)\n",
    "    common_strains = idxwhere((strain_rabund.loc[subject_sample_list + donor_sample_list] > thresh * 10).sum() >= 3)\n",
    "    focal_strains = list(set(donor_strain_list) | set(baseline_strain_list) | set(common_strains))\n",
    "\n",
    "    d0 = strain_rabund.loc[subject_sample_list].join(meta_all[['sample_type_specific']]).set_index('sample_type_specific')\n",
    "    d1 = pd.concat([d0, donor_mean_sample_rabund.to_frame('donor').T])\n",
    "    d2 = d1[focal_strains].assign(other=d1.sum(1) - d1[focal_strains].sum(1)).assign(x=sample_type_x).sort_values('x')\n",
    "    d3 = d2.drop('donor')\n",
    "\n",
    "    for strain in ['other'] + focal_strains:\n",
    "        ax.plot(d3['x'], d3[strain], c=strain_palette[strain], marker='o', alpha=0.7, lw=2)\n",
    "        if donor_sample_list:\n",
    "            ax.scatter(d2.loc['donor', 'x'], d2.loc['donor', strain], c=strain_palette[strain], marker='o', alpha=0.7, s=70)\n",
    "    ax.set_title(f\"{subject_id} ({donor_id})\")\n",
    "\n",
    "ax.set_yscale('symlog', linthresh=thresh)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "for ax in axs[-1]:\n",
    "    ax.set_xticks(sample_type_x.values)\n",
    "    ax.set_xticklabels(sample_type_x.index, rotation=45, ha='right')\n",
    "    \n",
    "fig.savefig(f'fig/ucfmt_engraftment_{species_id}.pdf', bbox_inches='tight')\n",
    "fig.savefig(f'fig/ucfmt_engraftment_{species_id}.png', dpi=400, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfacts",
   "language": "python",
   "name": "sfacts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}