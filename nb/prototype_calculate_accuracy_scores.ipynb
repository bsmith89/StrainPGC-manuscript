{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as _os\n",
    "_os.chdir(_os.environ['PROJECT_ROOT'])\n",
    "_os.path.realpath(_os.path.curdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "from lib.pandas_util import idxwhere, aligned_index, align_indexes, invert_mapping\n",
    "import matplotlib as mpl\n",
    "import lib.plot\n",
    "import statsmodels as sm\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "from tempfile import mkstemp\n",
    "import time\n",
    "import subprocess\n",
    "from itertools import chain\n",
    "import os\n",
    "from itertools import product\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sfacts as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.thisproject.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "plt.rcParams['figure.dpi'] = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters / Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_patterns = {}\n",
    "path_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new parameters.\n",
    "path_params.update(dict(\n",
    "    group_subset='xjin',\n",
    "    group='xjin_hmp2',\n",
    "    stemA='r.proc',\n",
    "))\n",
    "\n",
    "# Add new patterns.\n",
    "path_patterns.update(dict(\n",
    "    species_taxonomy=\"ref/gtpro/species_taxonomy_ext.tsv\",\n",
    "    all_species_depth_subset=\"data/group/{group_subset}/{stemA}.gtpro.species_depth.tsv\",\n",
    "    all_species_depth=\"data/group/{group}/{stemA}.gtpro.species_depth.tsv\",\n",
    "    midasdb_genomes=\"ref/uhgg_genomes_all_4644.tsv\",\n",
    "    strain_genomes=\"meta/genome.tsv\",\n",
    "))\n",
    "\n",
    "# This part is generic and should be run after ever new batch of path_patterns and path_params is added.\n",
    "path = {k: path_patterns[k].format(**path_params) for k in path_patterns}\n",
    "_path_exists = {}\n",
    "for p in path:\n",
    "    _path_exists[path[p]] = os.path.exists(path[p])\n",
    "assert all(_path_exists.values()), '\\n'.join([\"Missing files:\"] + [p for p in path_exists if not path_exists[p]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Species Abundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_depth = lib.thisproject.data.load_species_depth(path['all_species_depth'])\n",
    "species_depth_subset = lib.thisproject.data.load_species_depth(path['all_species_depth_subset'])\n",
    "rabund = species_depth.apply(lambda x: x / x.sum(), axis=1)\n",
    "rabund_subset = species_depth_subset.apply(lambda x: x / x.sum(), axis=1)\n",
    "\n",
    "n_species = 40\n",
    "top_species = (rabund_subset > 1e-5).sum().sort_values(ascending=False).head(n_species).index\n",
    "\n",
    "fig, axs = plt.subplots(n_species, figsize=(10, 0.5 * n_species), sharex=True, sharey=True)\n",
    "\n",
    "bins = np.logspace(-7, 0, num=51)\n",
    "\n",
    "for species_id, ax in zip(top_species, axs):\n",
    "    ax.hist(rabund_subset[species_id], bins=bins, alpha=0.7)\n",
    "    ax.hist(rabund[species_id], bins=bins, alpha=0.7)\n",
    "    ax.set_xscale('log')\n",
    "    prevalence = (rabund_subset[species_id] > 1e-5).mean()\n",
    "    ax.set_title(\"\")\n",
    "    # ax.set_xticks()\n",
    "    # ax.set_yticks()\n",
    "    ax.yaxis.set_visible(False)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.patch.set_alpha(0.0)\n",
    "    for spine in ['left', 'right', 'top', 'bottom']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "    ax.annotate(f'{species_id} ({prevalence:0.0%})', xy=(0.05, 0.1), ha='left', xycoords=\"axes fraction\")\n",
    "    ax.set_xlim(left=1e-7)\n",
    "    ax.set_ylim(top=300)\n",
    "    \n",
    "ax.xaxis.set_visible(True)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "\n",
    "fig.subplots_adjust(hspace=-0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_species = 40\n",
    "top_species = (species_depth_subset > 1e-3).sum().sort_values(ascending=False).head(n_species).index\n",
    "\n",
    "fig, axs = plt.subplots(n_species, figsize=(10, 0.5 * n_species), sharex=True, sharey=True)\n",
    "\n",
    "bins = np.logspace(-3, 4, num=51)\n",
    "\n",
    "for species_id, ax in zip(top_species, axs):\n",
    "    ax.hist(species_depth_subset[species_id], bins=bins, alpha=0.7)\n",
    "    ax.hist(species_depth[species_id], bins=bins, alpha=0.7)\n",
    "    ax.set_xscale('log')\n",
    "    prevalence = (species_depth_subset[species_id] > 1e-5).mean()\n",
    "    ax.set_title(\"\")\n",
    "    # ax.set_xticks()\n",
    "    # ax.set_yticks()\n",
    "    ax.yaxis.set_visible(False)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.patch.set_alpha(0.0)\n",
    "    for spine in ['left', 'right', 'top', 'bottom']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "    ax.annotate(f'{species_id} ({prevalence:0.0%})', xy=(0.05, 0.1), ha='left', xycoords=\"axes fraction\")\n",
    "    ax.set_xlim(left=1e-4)\n",
    "    ax.set_ylim(top=300)\n",
    "    \n",
    "ax.xaxis.set_visible(True)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "\n",
    "fig.subplots_adjust(hspace=-0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_species = 40\n",
    "second_species = (rabund_subset > 1e-5).sum().sort_values(ascending=False).head(n_species * 2).tail(n_species).index\n",
    "\n",
    "fig, axs = plt.subplots(n_species, figsize=(10, 0.5 * n_species), sharex=True, sharey=True)\n",
    "\n",
    "bins = np.logspace(-7, 0, num=51)\n",
    "\n",
    "for species_id, ax in zip(second_species, axs):\n",
    "    ax.hist(rabund_subset[species_id], bins=bins, alpha=0.7)\n",
    "    ax.hist(rabund[species_id], bins=bins, alpha=0.7)\n",
    "    ax.set_xscale('log')\n",
    "    prevalence = (rabund_subset[species_id] > 1e-5).mean()\n",
    "    ax.set_title(\"\")\n",
    "    # ax.set_xticks()\n",
    "    # ax.set_yticks()\n",
    "    ax.yaxis.set_visible(False)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.patch.set_alpha(0.0)\n",
    "    for spine in ['left', 'right', 'top', 'bottom']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "    ax.annotate(f'{species_id} ({prevalence:0.0%})', xy=(0.05, 0.1), ha='left', xycoords=\"axes fraction\")\n",
    "    ax.set_xlim(left=1e-7)\n",
    "    ax.set_ylim(top=300)\n",
    "    \n",
    "ax.xaxis.set_visible(True)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "\n",
    "fig.subplots_adjust(hspace=-0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_species = 40\n",
    "second_species = (species_depth_subset > 1e-3).sum().sort_values(ascending=False).head(n_species * 2).tail(n_species).index\n",
    "\n",
    "fig, axs = plt.subplots(n_species, figsize=(10, 0.5 * n_species), sharex=True, sharey=True)\n",
    "\n",
    "bins = np.logspace(-3, 4, num=51)\n",
    "\n",
    "for species_id, ax in zip(second_species, axs):\n",
    "    ax.hist(species_depth_subset[species_id], bins=bins, alpha=0.7)\n",
    "    ax.hist(species_depth[species_id], bins=bins, alpha=0.7)\n",
    "    ax.set_xscale('log')\n",
    "    prevalence = (species_depth_subset[species_id] > 1e-5).mean()\n",
    "    ax.set_title(\"\")\n",
    "    # ax.set_xticks()\n",
    "    # ax.set_yticks()\n",
    "    ax.yaxis.set_visible(False)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.patch.set_alpha(0.0)\n",
    "    for spine in ['left', 'right', 'top', 'bottom']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "    ax.annotate(f'{species_id} ({prevalence:0.0%})', xy=(0.05, 0.1), ha='left', xycoords=\"axes fraction\")\n",
    "    ax.set_xlim(left=1e-4)\n",
    "    ax.set_ylim(top=300)\n",
    "    \n",
    "ax.xaxis.set_visible(True)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "\n",
    "fig.subplots_adjust(hspace=-0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(species_depth_subset, norm=mpl.colors.PowerNorm(1/5), metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_depth_corr = pd.DataFrame(sp.spatial.distance.squareform(sp.spatial.distance.pdist(species_depth_subset.T, metric='cosine')), index=species_depth_subset.columns, columns=species_depth_subset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(1 - species_depth_corr, figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Focal Species (Manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = '100760'\n",
    "\n",
    "species_taxonomy = lib.thisproject.data.load_species_taxonomy(path[\"species_taxonomy\"])\n",
    "species_taxonomy.loc[species]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Ground-truth Reference Strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_genome = pd.read_table(path[\"strain_genomes\"], dtype='str')\n",
    "strain_genome[strain_genome.species_id == species]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_genome_ids = strain_genome[strain_genome.species_id == species].genome_id\n",
    "print(strain_genome_ids)\n",
    "strain_genome_id = strain_genome_ids.tolist()[0]\n",
    "assert strain_genome_ids.shape[0] == 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# FIXME: Hard-coded because the cell above doesn't account for multiple strains\n",
    "strain_genome_id = 'Bacteroides-dorei-DSM-17855_MAF-2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Gene Family Clustering-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new parameters.\n",
    "path_params.update(dict(\n",
    "    centroid=centroid,\n",
    "    species=species,\n",
    "    strain_genome_id=strain_genome_id,\n",
    "))\n",
    "\n",
    "# Add new patterns.\n",
    "path_patterns.update(dict(\n",
    "    strain_cds_length='data/species/sp-{species}/genome/{strain_genome_id}.prodigal-single.cds.nlength.tsv',\n",
    "    strain_x_uhgg_bitscore_ratio='data/species/sp-{species}/genome/{strain_genome_id}.midas_uhgg_pangenome-blastn.bitscore_ratio-c{centroid}.tsv',\n",
    "))\n",
    "\n",
    "# This part is generic and should be run after ever new batch of path_patterns and path_params is added.\n",
    "path = {k: path_patterns[k].format(**path_params) for k in path_patterns}\n",
    "_path_exists = {}\n",
    "for p in path:\n",
    "    _path_exists[path[p]] = os.path.exists(path[p])\n",
    "assert all(_path_exists.values()), '\\n'.join([\"Missing files:\"] + [p for p in _path_exists if not _path_exists[p]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set other SPGD parameters and check paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new parameters.\n",
    "path_params.update(dict(\n",
    "    stemB = 'filt-poly05-cvrg05.ss-g10000-block0-seed0.fit-sfacts37-s85-seed0',\n",
    "    # stemC = 'sfacts42-seed0',\n",
    "    gene_params = f\"99-v22-agg{centroid}\",\n",
    "    # thresh_params = 'thresh-corrq10-depth300',\n",
    "    corr_thresh=\"350\",\n",
    "    depth_thresh=\"250\",\n",
    "    specgene_params='specgene-ref-t25-p95',\n",
    "    ss_params=\"all\",\n",
    "    # ss_params=\"deepest-n10\",\n",
    "))\n",
    "\n",
    "# Add new patterns.\n",
    "path_patterns.update(dict(\n",
    "    flag=\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.{stemB}.gene{gene_params}.spgc_{specgene_params}_ss-{ss_params}_thresh-corr{corr_thresh}-depth{depth_thresh}.strain_files.flag\",\n",
    "    fit=\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.{stemB}.world.nc\",\n",
    "    # refit=\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.{stemB}.refit-{stemC}.world.nc\",\n",
    "    strain_correlation=\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.{stemB}.gene{gene_params}.spgc_{specgene_params}_ss-{ss_params}.strain_correlation.tsv\",\n",
    "    strain_depth_ratio=\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.{stemB}.gene{gene_params}.spgc_{specgene_params}_ss-{ss_params}.strain_depth_ratio.tsv\",\n",
    "    strain_fraction=\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.{stemB}.comm.tsv\",\n",
    "    species_gene_mean_depth=\"data/group/{group}/species/sp-{species}/{stemA}.gene{gene_params}.spgc_{specgene_params}.species_depth.tsv\",\n",
    "    species_gtpro_depth=\"data/group/{group}/{stemA}.gtpro.species_depth.tsv\",\n",
    "    species_correlation=\"data/group/{group}/species/sp-{species}/{stemA}.gene{gene_params}.spgc_specgene-denovo2-t30-n500.species_correlation.tsv\",\n",
    "    species_gene=\"data/group/{group}/species/sp-{species}/{stemA}.gene{gene_params}.spgc_{specgene_params}.species_gene.list\",\n",
    "    species_gene_denovo=\"data/group/{group}/species/sp-{species}/{stemA}.gene{gene_params}.spgc_specgene-denovo-n500.species_gene.list\",\n",
    "    species_gene_denovo2=\"data/group/{group}/species/sp-{species}/{stemA}.gene{gene_params}.spgc_specgene-denovo2-t30-n500.species_gene.list\",\n",
    "    species_gene_reference=\"data/group/{group}/species/sp-{species}/{stemA}.gene{gene_params}.spgc_specgene-ref-t25-p95.species_gene.list\",\n",
    "    species_free_samples=\"data/group/{group}/species/sp-{species}/{stemA}.gene{gene_params}.spgc_specgene-ref-t25-p95.species_free_samples.list\",\n",
    "    strain_samples=\"data/group/{group}/species/sp-{species}/r.proc.gtpro.{stemB}.spgc_ss-{ss_params}.strain_samples.tsv\",\n",
    "    strain_thresholds=\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.{stemB}.gene{gene_params}.spgc_{specgene_params}_ss-{ss_params}_thresh-corr{corr_thresh}-depth{depth_thresh}.strain_gene_threshold.tsv\",\n",
    "    gene_annotations=\"ref/midasdb_uhgg_gene_annotations/sp-{species}.gene{centroid}_annotations.tsv\",\n",
    "    # raw_gene_depth=\"data/group/{group}/species/sp-{species}/{stemA}.pangenome95.gene{centroid}_depth.nc\",\n",
    "    # norm_gene_depth=\"data/group/{group}/species/sp-{species}/{stemA}.gene99-mapq0-agg{centroid}.normed_depth2.nc\",\n",
    "    raw_gene_depth=\"data/group/{group}/species/sp-{species}/{stemA}.gene{gene_params}.depth2.nc\",\n",
    "    # raw_gene_depth=\"data/group/{group}/species/sp-{species}/{stemA}.gene{centroid}.normed_depth2.nc\",\n",
    "    reference_copy_number=\"ref/midasdb_uhgg_pangenomes/{species}/gene{centroid}.reference_copy_number.nc\",\n",
    "    cluster_info=\"ref/midasdb_uhgg/pangenomes/{species}/cluster_info.txt\",\n",
    "    gtpro_reference_genotype=\"data/species/sp-{species}/gtpro_ref.mgtp.nc\",\n",
    "    reference_strain_accuracy=\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.{stemB}.gene{gene_params}.spgc_{specgene_params}_ss-{ss_params}_thresh-corr{corr_thresh}-depth{depth_thresh}.{strain_genome_id}.gene_content_reconstruction_accuracy.tsv\",\n",
    "    reference_strain_accuracy_depth_only=\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.{stemB}.gene{gene_params}.spgc_{specgene_params}_ss-{ss_params}_thresh-corr0-depth{depth_thresh}.{strain_genome_id}.gene_content_reconstruction_accuracy.tsv\",\n",
    "    # reference_strain_mapping_q0=\"data/group/{group}/species/sp-{species}/ALL_STRAINS.tiles-l100-o99.gene99-mapq0-agg{centroid}.depth2.nc\",\n",
    "    reference_strain_mapping_q0=\"data/group/{group}/species/sp-{species}/ALL_STRAINS.tiles-l100-o99.gene{gene_params}.depth2.nc\",\n",
    "    # reference_strain_mapping_q1=\"data/group/{group}/species/sp-{species}/ALL_STRAINS.tiles-l100-o99.gene99-mapq1-agg{centroid}.depth2.nc\",\n",
    "    # reference_strain_mapping_q2=\"data/group/{group}/species/sp-{species}/ALL_STRAINS.tiles-l100-o99.gene99-mapq2-agg{centroid}.depth2.nc\",\n",
    "    # reference_strain_mapping_q4=\"data/group/{group}/species/sp-{species}/ALL_STRAINS.tiles-l100-o99.gene99-mapq4-agg{centroid}.depth2.nc\",\n",
    "    xjin_benchmarking=\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.{stemB}.gene{gene_params}.spgc_{specgene_params}_ss-xjin-{ss_params}_thresh-corr{corr_thresh}-depth{depth_thresh}.xjin_strain_summary.tsv\",\n",
    "))\n",
    "\n",
    "# This part is generic and should be run after ever new batch of path_patterns and path_params is added.\n",
    "path = {k: path_patterns[k].format(**path_params) for k in path_patterns}\n",
    "_path_exists = {}\n",
    "for p in path:\n",
    "    _path_exists[path[p]] = os.path.exists(path[p])\n",
    "assert all(_path_exists.values()), '\\n'.join([\"Missing files:\"] + [p for p in _path_exists if not _path_exists[p]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path['species_free_samples']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path['flag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SFacts results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = sf.World.load(path['fit'])\n",
    "print(fit.sizes)\n",
    "np.random.seed(0)\n",
    "position_ss = fit.random_sample(position=min(fit.sizes['position'], 1000)).position\n",
    "\n",
    "\n",
    "fit_subset = fit.sel(sample=list(set(species_depth_subset.index) & set(fit.sample.values)))\n",
    "\n",
    "# fuzzy_geno = sf.Genotype.load(path['fit'])  # FIXME: refit\n",
    "# fuzzy_geno = sf.World.from_combined(fuzzy_geno, fit.metagenotype, fit.community)\n",
    "\n",
    "sf.evaluation.metagenotype_error2(fit)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sf.plot.plot_metagenotype(\n",
    "    (\n",
    "        fit\n",
    "        .drop_low_abundance_strains(0.05)\n",
    "        .sel(position=position_ss)\n",
    "    ),\n",
    "    # scaley=0.2,\n",
    "    # scalex=0.3,\n",
    "    row_linkage_func=lambda w: w.metagenotype.linkage(\"position\"),\n",
    "    col_linkage_func=lambda w: w.metagenotype.linkage(\"sample\"),\n",
    ")\n",
    "# sf.plot.plot_depth(\n",
    "#     fit.sel(position=position_ss),\n",
    "#     # scaley=0.2, scalex=0.3,\n",
    "#     row_linkage_func=lambda w: w.metagenotype.linkage(\"position\"),\n",
    "#     col_linkage_func=lambda w: w.community.linkage(),\n",
    "# )\n",
    "# sf.plot.plot_dominance(\n",
    "#     fit.sel(position=position_ss),\n",
    "#     # scaley=0.2, scalex=0.3,\n",
    "#     row_linkage_func=lambda w: w.metagenotype.linkage(\"position\"),\n",
    "#     col_linkage_func=lambda w: w.community.linkage(),\n",
    "# )\n",
    "sf.plot.plot_community(\n",
    "    (\n",
    "        fit\n",
    "        .drop_low_abundance_strains(0.05)\n",
    "        .sel(position=position_ss)\n",
    "    ),\n",
    "    scaley=0.3,\n",
    "    # scalex=0.3,\n",
    "    col_linkage_func=lambda w: w.metagenotype.linkage(\"sample\"),\n",
    "    row_linkage_func=lambda w: fit.drop_low_abundance_strains(0.05).genotype.linkage(\"strain\"),\n",
    ")\n",
    "sf.plot.plot_genotype(\n",
    "    (\n",
    "        fit\n",
    "        .drop_low_abundance_strains(0.05)\n",
    "        .sel(position=position_ss)\n",
    "    ),\n",
    "    scaley=0.2,\n",
    "    # scalex=0.3,\n",
    "    col_linkage_func=lambda w: w.metagenotype.linkage(\"position\"),\n",
    "    row_linkage_func=lambda w: fit.drop_low_abundance_strains(0.05).genotype.linkage(\"strain\"),\n",
    ")\n",
    "\n",
    "sf.plot.plot_genotype(\n",
    "    (\n",
    "        fit\n",
    "        .drop_low_abundance_strains(0.05)\n",
    "        .sel(position=position_ss)\n",
    "    ),\n",
    "    scaley=0.2,\n",
    "    # scalex=0.3,\n",
    "    col_linkage_func=lambda w: w.metagenotype.linkage(\"position\"),\n",
    "    row_linkage_func=lambda w: fit.drop_low_abundance_strains(0.05).genotype.linkage(\"strain\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify focal sfacts strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fit_subset.community.mean(\"sample\").to_series().sort_values(ascending=False).head(5))\n",
    "top_inferred_strain = fit_subset.community.mean(\"sample\").to_series().idxmax()\n",
    "\n",
    "assert fit_subset.community.mean(\"sample\").sel(strain=top_inferred_strain) > 0.9"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# FIXME: Hard-coded because the cell above doesn't account for multiple strains\n",
    "top_inferred_strain = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.read_table(path['reference_strain_accuracy'], index_col=0).sort_values('f1', ascending=False).loc[top_inferred_strain, ['precision', 'recall', 'f1']])\n",
    "pd.read_table(path['reference_strain_accuracy'], index_col=0).sort_values('f1', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gene Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_cluster = pd.read_table(\n",
    "    path[\"cluster_info\"]\n",
    ").set_index('centroid_99', drop=False).rename_axis(index='gene_id')\n",
    "gene_annotation = pd.read_table(\n",
    "    path[\"gene_annotations\"],\n",
    "    names=['locus_tag', 'ftype', 'length_bp', 'gene', 'EC_number', 'COG', 'product'],\n",
    "    index_col='locus_tag',\n",
    ").rename(columns=str.lower)\n",
    "\n",
    "gene_meta = gene_cluster.loc[gene_cluster[f'centroid_{centroid}'].unique()].join(gene_annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference Strain Gene Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blastp_header_names = [\n",
    "    'qseqid',\n",
    "    'sseqid',\n",
    "    'pident',\n",
    "    'length',\n",
    "    'mismatch',\n",
    "    'gapopen',\n",
    "    'qstart',\n",
    "    'qend',\n",
    "    'sstart',\n",
    "    'send',\n",
    "    'evalue',\n",
    "    'bitscore'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orf_length = pd.read_table(path['strain_cds_length'], names=['orf', 'length'], index_col=['orf']).squeeze()\n",
    "\n",
    "orf_x_midas = pd.read_table(path['strain_x_uhgg_bitscore_ratio'], index_col=['orf', 'gene']).squeeze()\n",
    "# orf_x_midas = pd.read_table('data/species/sp-101380/genome/Ruminococcus-gnavus-ATCC-29149_MinIONHybrid.midas_uhgg_pangenome-blastp.bitscore_ratio-c75.tsv', index_col=['orf', 'gene']).squeeze()\n",
    "\n",
    "\n",
    "# _strain_x_strain = (\n",
    "#     pd.read_table(\n",
    "#         path['strain_x_strain'],\n",
    "#         names=blastp_header_names\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# _max_bitscore = _strain_x_strain.groupby(['qseqid']).bitscore.max()\n",
    "\n",
    "# strain_x_uhgg = (\n",
    "#     pd.read_table(\n",
    "#         path['strain_x_uhgg'],\n",
    "#         names=blastp_header_names\n",
    "#     )\n",
    "#     .assign(bitscore_ratio=lambda x: x.bitscore / x.qseqid.map(_max_bitscore))\n",
    "#     .assign(sseq_centroid=lambda x: x.sseqid.map(gene_cluster[f'centroid_{centroid}']))\n",
    "# )\n",
    "\n",
    "# best_uhgg_hit = strain_x_uhgg.groupby('qseqid').apply(lambda d: d.sort_values('bitscore').iloc[-1]).groupby('sseq_centroid').bitscore_ratio.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orf_x_midas = strain_x_uhgg.groupby(['qseqid', 'sseq_centroid']).bitscore_ratio.max()\n",
    "\n",
    "\n",
    "bins = np.linspace(0, 1)\n",
    "plt.hist(orf_x_midas.unstack(fill_value=0).max(0), bins=bins, density=True)\n",
    "plt.hist(orf_x_midas.unstack(fill_value=0).max(1), bins=bins, density=True, alpha=0.5)\n",
    "plt.yscale('log')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(orf_x_midas.unstack().astype(float) > 0.95).sum(1).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strain-specific correlations/depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_corr = pd.read_table(path[\"strain_correlation\"], index_col=['gene_id', 'strain']).squeeze().unstack('strain', fill_value=0)\n",
    "strain_depth = pd.read_table(\n",
    "    path[\"strain_depth_ratio\"],\n",
    "    index_col=['gene_id', 'strain']\n",
    ").squeeze().unstack()\n",
    "# strain_corr, strain_depth = align_indexes(*align_indexes(strain_corr, strain_depth), axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strain Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_thresholds = (\n",
    "    pd.read_table(path[\"strain_thresholds\"], index_col='strain')\n",
    "    .rename(columns=dict(\n",
    "        # correlation_strict='corr_threshold_strict',\n",
    "        correlation='corr_threshold',\n",
    "        # correlation_lenient='corr_threshold_lenient',\n",
    "        depth_high='depth_thresh_high',\n",
    "        depth_low='depth_thresh_low',\n",
    "    ))\n",
    ")\n",
    "\n",
    "_strain_meta = (\n",
    "    strain_thresholds\n",
    "    .join(fit.genotype.entropy().to_series().rename('genotype_entropy'))\n",
    "    # .join(refit.genotype.entropy().to_series().rename('genotype_refit_entropy'))\n",
    "    # .join(fit.metagenotype.entropy().to_series().rename('metagenotype_entropy').groupby(sample_to_strain).mean().rename(int))\n",
    "    # .join(strain_to_sample_list.apply(len).rename('num_samples'))\n",
    "    # .join(species_depth.apply(lambda x: x**(1)).groupby(sample_to_strain).std().rename('depth_stdev').rename(int))\n",
    "    # .join(species_depth.apply(lambda x: x**(1)).groupby(sample_to_strain).max().rename('depth_max').rename(int))\n",
    "    # .join(species_depth.apply(lambda x: x**(1)).groupby(sample_to_strain).sum().rename('depth_sum').rename(int))\n",
    "    # .assign(power_index=lambda x: (x.depth_stdev * np.sqrt(x.num_samples)).fillna(0))\n",
    ")\n",
    "strain_meta = _strain_meta\n",
    "\n",
    "\n",
    "# power_index_thresh = 5\n",
    "# genotype_entropy_thresh = 0.2\n",
    "# genotype_refit_entropy_thresh = 1.0\n",
    "\n",
    "# high_power_strain_list = idxwhere(\n",
    "#     (strain_meta.power_index > power_index_thresh)\n",
    "#     & (strain_meta.genotype_entropy < genotype_entropy_thresh)\n",
    "#     & (strain_meta.genotype_refit_entropy < genotype_refit_entropy_thresh)\n",
    "# )\n",
    "# print(len(high_power_strain_list))\n",
    "# highest_power_strain_list = strain_meta.sort_values('power_index', ascending=False).head(3).index\n",
    "\n",
    "# plt.scatter(strain_meta.power_index, strain_meta.corr_threshold, c=strain_meta.genotype_refit_entropy, alpha=0.5)\n",
    "# plt.axvline(power_index_thresh, lw=1, linestyle='--', color='k')\n",
    "# plt.colorbar()\n",
    "# plt.xscale('log')\n",
    "\n",
    "strain_meta#.loc[[top_inferred_strain]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "strain_corr_q = pd.read_table(path['strain_corr_quantile'], index_col='gene_id')\n",
    "strain_corr_q.columns = strain_corr_q.columns.astype(int)\n",
    "strain_depth_q = pd.read_table(path['strain_depth_quantile'], index_col='gene_id')\n",
    "strain_depth_q.columns = strain_depth_q.columns.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_corr = pd.read_table(path[\"species_correlation\"], names=['sample', 'correlation'], index_col='sample').squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPGC Species Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path[\"species_gene\"]) as f:\n",
    "    species_gene_hit = [line.strip() for line in f]\n",
    "    \n",
    "with open(path[\"species_gene_denovo\"]) as f:\n",
    "    species_gene_denovo_hit = [line.strip() for line in f]\n",
    "\n",
    "with open(path[\"species_gene_denovo2\"]) as f:\n",
    "# with open(\"data/group/xjin_hmp2/species/sp-100203/r.proc.gtpro.filt-poly05-cvrg05.ss-g10000-block0-seed0.fit-sfacts37-s85-seed0.gene99-v22-agg75.spgc.species_gene2-n500.list\") as f:\n",
    "    species_gene_denovo_hit2 = [line.strip() for line in f]\n",
    "\n",
    "with open(path[\"species_gene_reference\"]) as f:\n",
    "    species_gene_reference_hit = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strain gene definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_strain_tile_depth_q0 = xr.load_dataarray(path['reference_strain_mapping_q0']).sel(sample=f'sp-{species}/genome/{strain_genome_id}')\n",
    "# reference_strain_tile_depth_q1 = xr.load_dataarray(path['reference_strain_mapping_q1']).sel(sample=f'sp-{species}/genome/{strain_genome_id}')\n",
    "# reference_strain_tile_depth_q2 = xr.load_dataarray(path['reference_strain_mapping_q2']).sel(sample=f'sp-{species}/genome/{strain_genome_id}')\n",
    "# reference_strain_tile_depth_q4 = xr.load_dataarray(path['reference_strain_mapping_q4']).sel(sample=f'sp-{species}/genome/{strain_genome_id}')\n",
    "\n",
    "bins = np.logspace(-1, 3, num=100)\n",
    "plt.hist(reference_strain_tile_depth_q0 + 1e-1, bins=bins, alpha=0.5)\n",
    "plt.hist(reference_strain_tile_depth_q0.reindex(gene_id=species_gene_hit, fill_value=0) + 1e-1, bins=bins, alpha=0.5)\n",
    "# plt.hist(reference_strain_tile_depth_q1, bins=np.logspace(-3, 3, num=50), alpha=0.5)\n",
    "# plt.hist(reference_strain_tile_depth_q2, bins=np.logspace(-3, 3, num=50), alpha=0.5)\n",
    "# plt.hist(reference_strain_tile_depth_q4, bins=np.logspace(-3, 3, num=50), alpha=0.5)\n",
    "# plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.axvline(200, lw=1, linestyle='-', color='k')\n",
    "plt.axvline(50, lw=1, linestyle='--', color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-gene Strain Corr/Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_strain = top_inferred_strain\n",
    "\n",
    "depth_threshold = strain_meta.depth_thresh_low.loc[_strain]\n",
    "corr_threshold = strain_meta.corr_threshold.loc[_strain]\n",
    "# corr_threshold = 0.95  # Set manually, but this could/should be the automatically selected threshold.\n",
    "# depth_threshold = 0.2  # Set manually, but this could/should be the automatically selected threshold.\n",
    "bitscore_threshold = 0.95\n",
    "tile_depth_threshold = 30\n",
    "\n",
    "strain_scores = (\n",
    "    pd.DataFrame(dict(\n",
    "        bitscore_ratio=orf_x_midas.unstack(fill_value=0).max(),\n",
    "        strain_corr=strain_corr[_strain],\n",
    "        strain_depth=strain_depth[_strain],\n",
    "        species_corr=species_corr,\n",
    "        tile_depth_q0=reference_strain_tile_depth_q0.to_series().reindex(strain_corr.index, fill_value=0),\n",
    "        # tile_depth_q1=reference_strain_tile_depth_q1.to_series().reindex(strain_corr.index, fill_value=0),\n",
    "        # tile_depth_q2=reference_strain_tile_depth_q2.to_series().reindex(strain_corr.index, fill_value=0),\n",
    "        # tile_depth_q4=reference_strain_tile_depth_q4.to_series().reindex(strain_corr.index, fill_value=0),\n",
    "        # strain_corr_q=strain_corr_q[_strain],\n",
    "        # strain_depth_q=strain_depth_q[_strain],\n",
    "    ))\n",
    "    .fillna(0)\n",
    "    .assign(\n",
    "        bitscore_hit=lambda x: x.bitscore_ratio >= bitscore_threshold,\n",
    "        not_bitscore_hit=lambda x: x.bitscore_ratio < bitscore_threshold,\n",
    "        tile_depth_hit=lambda x: x.tile_depth_q0 >= tile_depth_threshold,\n",
    "        not_tile_depth_hit=lambda x: x.tile_depth_q0 < tile_depth_threshold,\n",
    "        depth_hit=lambda x: (x.strain_depth > depth_threshold),\n",
    "        corr_and_depth_hit=lambda x: (x.strain_corr > corr_threshold) & (x.strain_depth > depth_threshold),\n",
    "        species_gene=lambda x: x.index.to_series().isin(species_gene_hit),\n",
    "        species_gene_denovo=lambda x: x.index.to_series().isin(species_gene_denovo_hit),\n",
    "        species_gene_denovo2=lambda x: x.index.to_series().isin(species_gene_denovo_hit2),\n",
    "        species_gene_reference=lambda x: x.index.to_series().isin(species_gene_reference_hit),\n",
    "        corr_complement=lambda x: 1 - x.strain_corr,\n",
    "        # log_tile_depth=lambda x: np.log10(x.tile_depth + 1e-4),\n",
    "        dummy=False,\n",
    "        gene_length=gene_cluster.groupby(f'centroid_{centroid}').centroid_99_length.mean(),\n",
    "    )\n",
    "    .sort_values('bitscore_ratio')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_list = [\n",
    "        'bitscore_hit',\n",
    "        'not_bitscore_hit',\n",
    "        'tile_depth_hit',\n",
    "        'not_tile_depth_hit',\n",
    "        'species_gene',\n",
    "        'species_gene_denovo',\n",
    "        'species_gene_denovo2',\n",
    "        'species_gene_reference',\n",
    "        'gene_length',\n",
    "        'tile_depth_q0',\n",
    "        # 'tile_depth_q2',\n",
    "    ]\n",
    "\n",
    "fig, axs = lib.plot.subplots_grid(ncols=2, naxes=len(indicator_list), ax_width=6, ax_height=4, sharex=True, sharey=True)\n",
    "\n",
    "for ax, c in zip(\n",
    "    axs.flatten(),\n",
    "    indicator_list,\n",
    "):\n",
    "    \n",
    "    cax = make_axes_locatable(ax).append_axes('right', size='5%', pad=0.05)\n",
    "    artist = ax.scatter(\n",
    "        'corr_complement',\n",
    "        'strain_depth',\n",
    "        data=strain_scores.sort_values(c),\n",
    "        s=1,\n",
    "        c=c,\n",
    "        alpha=0.9,\n",
    "        cmap='rainbow',\n",
    "        norm=mpl.colors.SymLogNorm(linthresh=1e-4),\n",
    "    )\n",
    "    cbar = fig.colorbar(artist, cax=cax)\n",
    "    cbar.solids.set_alpha(1.0)\n",
    "    ax.axhline(depth_threshold, lw=1, linestyle='--')\n",
    "    ax.axhline(1, xmin=0., xmax=0.5, lw=1, linestyle='--', color='k')\n",
    "    ax.axvline(1 - corr_threshold, lw=1, linestyle='--')\n",
    "    ax.set_xscale('symlog', linthresh=1e-3)\n",
    "    ax.set_title(c)\n",
    "    # TODO: xscale logit?\n",
    "    ax.set_yscale('symlog', linthresh=1e-2)\n",
    "    ax.set_ylim(bottom=0)\n",
    "ax.invert_xaxis()\n",
    "ax.set_xlabel('correlation')\n",
    "ax.set_ylabel('depth ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "kde_refs = KernelDensity().fit(strain_scores.loc[lambda x: x.species_gene_reference][['strain_corr', 'strain_depth']].values)\n",
    "kde_not_refs = KernelDensity().fit(strain_scores[['strain_corr', 'strain_depth']].values)\n",
    "\n",
    "res_x = 50\n",
    "res_y = 50\n",
    "xx, yy = np.meshgrid(np.linspace(0, 1, num=res_x), np.linspace(0, 1, num=res_y))\n",
    "mesh_flat = np.stack((xx, yy), axis=2).reshape((-1,2))\n",
    "loglik_given_refs = kde_refs.score_samples(mesh_flat)\n",
    "loglik_given_not_refs = kde_not_refs.score_samples(mesh_flat)\n",
    "\n",
    "fig, axs = plt.subplots(2, figsize=(5, 10))\n",
    "\n",
    "ax = axs[0]\n",
    "cax = make_axes_locatable(ax).append_axes('right', size='5%', pad=0.05)\n",
    "artist = ax.pcolormesh(xx[0,:], yy[:,0], np.exp(loglik_given_refs.reshape((res_x, res_y))), vmin=0, vmax=0.2)\n",
    "cbar = fig.colorbar(artist, cax=cax)\n",
    "\n",
    "ax = axs[1]\n",
    "cax = make_axes_locatable(ax).append_axes('right', size='5%', pad=0.05)\n",
    "artist = ax.pcolormesh(xx[0,:], yy[:,0], np.exp(loglik_given_not_refs.reshape((res_x, res_y))), vmin=0, vmax=0.2)\n",
    "cbar = fig.colorbar(artist, cax=cax)\n",
    "\n",
    "\n",
    "def posteriorA(points, priorA, kdeA, kdeB):\n",
    "    numerator = priorA * np.exp(kdeA.score_samples(points))\n",
    "    denominator = numerator + (1 - priorA) * np.exp(kdeB.score_samples(points))\n",
    "    return numerator/denominator\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, figsize=(5, 10))\n",
    "\n",
    "ax = axs[0]\n",
    "cax = make_axes_locatable(ax).append_axes('right', size='5%', pad=0.05)\n",
    "artist = ax.pcolormesh(xx[0,:], yy[:,0], posteriorA(mesh_flat, 0.5, kde_refs, kde_not_refs).reshape((res_x, res_y)))\n",
    "cbar = fig.colorbar(artist, cax=cax)\n",
    "\n",
    "ax = axs[1]\n",
    "cax = make_axes_locatable(ax).append_axes('right', size='5%', pad=0.05)\n",
    "artist = ax.pcolormesh(xx[0,:], yy[:,0], posteriorA(mesh_flat, 0.9, kde_refs, kde_not_refs).reshape((res_x, res_y)))\n",
    "cbar = fig.colorbar(artist, cax=cax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_complement_thresh_list = np.logspace(-3, 0, num=50)\n",
    "depth_thresh_list = np.logspace(-2, 0, num=50)\n",
    "fig, axs = plt.subplots(3, 3, figsize=(20, 15), sharex=True, sharey=True)\n",
    "\n",
    "for (indicator_name, indicator_hit), ax_col in zip(\n",
    "    dict(\n",
    "        tile_depth_hit=idxwhere(reference_strain_tile_depth_q0.to_series() > 30),\n",
    "        species_gene_reference_hit=species_gene_reference_hit,\n",
    "        species_gene_hit=species_gene_hit,\n",
    "    ).items(),\n",
    "    axs.T,\n",
    "):\n",
    "    ax_col[0].set_title(indicator_name)\n",
    "    both_exclude = np.empty((len(corr_complement_thresh_list), len(depth_thresh_list)))\n",
    "    indicator_include = np.empty((len(corr_complement_thresh_list), len(depth_thresh_list)))\n",
    "    for (i, corr_complement_t), (j, depth_t) in product(\n",
    "        enumerate(corr_complement_thresh_list),\n",
    "        enumerate(depth_thresh_list)\n",
    "    ):\n",
    "        d = (\n",
    "            strain_scores\n",
    "            [['strain_corr', 'strain_depth']]\n",
    "            .assign(\n",
    "                both_exclude=lambda x: (x.strain_corr < (1 - corr_complement_t)) & (x.strain_depth < depth_t),\n",
    "                both_include=lambda x: (x.strain_corr > (1 - corr_complement_t)) & (x.strain_depth > depth_t),\n",
    "            )\n",
    "        )\n",
    "        both_exclude[i, j] = d.both_exclude.sum()\n",
    "        indicator_include[i, j] = d.reindex(indicator_hit).both_include.sum()\n",
    "    both_exclude = (\n",
    "        pd.DataFrame(both_exclude, index=corr_complement_thresh_list, columns=depth_thresh_list)\n",
    "        .rename_axis(index='corr_complement_thresh', columns='depth_thresh')\n",
    "    )\n",
    "    indicator_include = (\n",
    "        pd.DataFrame(indicator_include, index=corr_complement_thresh_list, columns=depth_thresh_list)\n",
    "        .rename_axis(index='corr_complement_thresh', columns='depth_thresh')\n",
    "    )\n",
    "    \n",
    "    \n",
    "    _a = 2\n",
    "    both_exclude_trnsf = np.log(both_exclude + 1)\n",
    "    indicator_include_trnsf = np.log(indicator_include + 1)\n",
    "    _corr_complement_thresh, _depth_thresh = (both_exclude_trnsf + _a * indicator_include_trnsf).stack().idxmax()\n",
    "    _corr_thresh = 1 - _corr_complement_thresh\n",
    "    \n",
    "    for d, ax in zip([both_exclude_trnsf, indicator_include_trnsf, both_exclude_trnsf + _a * indicator_include_trnsf], ax_col):\n",
    "        cax = make_axes_locatable(ax).append_axes('right', size='5%', pad=0.25)\n",
    "        artist = ax.pcolormesh(d.index, d.columns, d.T, norm=mpl.colors.PowerNorm(3))\n",
    "        cbar = fig.colorbar(artist, cax=cax)\n",
    "        ax.scatter(_corr_complement_thresh, _depth_thresh, color='r')\n",
    "    print(f\"{indicator_name}: corr_thresh={_corr_thresh}, depth_thresh={_depth_thresh}\")\n",
    "        \n",
    "axs[0, 0].set_xscale('log')\n",
    "axs[0, 0].invert_xaxis()\n",
    "axs[0, 0].set_yscale('log')\n",
    "axs[0, 0].set_ylabel('exclude')\n",
    "axs[1, 0].set_ylabel('include')\n",
    "axs[2, 0].set_ylabel('product')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_list = [\n",
    "        'bitscore_hit',\n",
    "        'not_bitscore_hit',\n",
    "        'tile_depth_hit',\n",
    "        'not_tile_depth_hit',\n",
    "        'species_gene_denovo2',\n",
    "        'species_gene_reference',\n",
    "        'tile_depth_q0',\n",
    "    ]\n",
    "\n",
    "fig, axs = lib.plot.subplots_grid(ncols=2, naxes=len(indicator_list), ax_width=6, ax_height=4, sharex=True, sharey=True)\n",
    "\n",
    "for ax, c in zip(\n",
    "    axs.flatten(),\n",
    "    indicator_list,\n",
    "):\n",
    "    \n",
    "    cax = make_axes_locatable(ax).append_axes('right', size='5%', pad=0.05)  \n",
    "    artist = ax.scatter(\n",
    "        'corr_complement',\n",
    "        'strain_depth',\n",
    "        data=strain_scores.sort_values(c),\n",
    "        s=1,\n",
    "        c=c,\n",
    "        alpha=0.9,\n",
    "        cmap='rainbow',\n",
    "        norm=mpl.colors.SymLogNorm(linthresh=1e-4),\n",
    "    )\n",
    "    cbar = fig.colorbar(artist, cax=cax)\n",
    "    cbar.solids.set_alpha(1.0)\n",
    "    ax.axhline(1, xmin=0., xmax=0.5, lw=1, linestyle='--', color='k')\n",
    "\n",
    "    ax.axhline(_depth_thresh, lw=1, linestyle='-')\n",
    "    ax.axvline(_corr_complement_thresh, lw=1, linestyle='-')\n",
    "    ax.axhline(depth_threshold, lw=1, linestyle='--')\n",
    "    ax.axvline(1 - corr_threshold, lw=1, linestyle='--')\n",
    "    \n",
    "    ax.set_title(c)\n",
    "    # TODO: xscale logit?\n",
    "    ax.set_yscale('symlog', linthresh=1e-2)\n",
    "    # ax.set_xscale('logit')\n",
    "    ax.set_xscale('symlog', linthresh=1e-2)\n",
    "    ax.set_ylim(bottom=0)\n",
    "ax.invert_xaxis()\n",
    "ax.set_xlabel('correlation')\n",
    "ax.set_ylabel('depth ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: How to pick cutoffs (Laplace Smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(-4, 0, num=100)\n",
    "\n",
    "x = np.log10((1 - strain_scores[lambda x: x.species_gene_denovo2].strain_corr) + 1e-5)\n",
    "mean_finit_x = x[np.isfinite(x)].mean()\n",
    "x = x.replace({-np.inf: mean_finit_x, 0: mean_finit_x})\n",
    "# x = sp.special.expit(strain_scores[lambda x: x.species_gene_denovo2].strain_corr)\n",
    "\n",
    "\n",
    "kappa0, loc0, scale0 = sp.stats.laplace_asymmetric.fit(x)\n",
    "# kappa1, loc1, scale1 = sp.stats.laplace_asymmetric.fit(x, f0=1)\n",
    "\n",
    "dist0 = sp.stats.laplace_asymmetric(kappa=kappa0, loc=loc0, scale=scale0)\n",
    "dist1 = sp.stats.laplace_asymmetric(kappa=1, loc=loc0, scale=scale0)\n",
    "\n",
    "\n",
    "plt.hist(x, bins=bins, density=True)\n",
    "plt.axvline(dist0.ppf(0.99), color='k')\n",
    "plt.axvline(dist1.ppf(0.99), color='k', linestyle='--')\n",
    "plt.plot(bins, dist0.pdf(bins))\n",
    "plt.plot(bins, dist1.pdf(bins))\n",
    "\n",
    "print(kappa0, loc0, scale0)\n",
    "print(1 - 10 ** dist0.ppf(0.99))\n",
    "\n",
    "# print(kappa1, loc1, scale1)\n",
    "print(1 - 10 ** dist1.ppf(0.99))\n",
    "\n",
    "\n",
    "# plt.yscale('symlog', linthresh=1e-2, linscale=0.1)\n",
    "# plt.xscale('log')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(strain_scores[lambda x: x.species_gene_denovo2].strain_corr).sort_values().tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(strain_scores[lambda x: x.species_gene_denovo2].strain_corr, bins=200)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qq = np.linspace(0, 1, num=len(x))\n",
    "x = np.log10(1 - strain_scores[lambda x: x.species_gene_denovo2].strain_corr.sort_values(ascending=False))\n",
    "plt.plot([0, 1], [0, 1], lw=1, c='k')\n",
    "plt.scatter(qq, dist0.cdf(x), s=1)\n",
    "plt.scatter(qq, dist1.cdf(x), s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(-2, 1, num=100)\n",
    "\n",
    "x = np.log10(strain_scores[lambda x: x.species_gene_denovo2].strain_depth)\n",
    "y = np.log10(strain_scores[lambda x: x.species_gene_reference].strain_depth)\n",
    "plt.hist(x, bins=bins, density=True)\n",
    "plt.hist(y, bins=bins, density=True, alpha=0.5)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D Thresholding"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n = 50\n",
    "thresh_list = np.linspace(0, 0.1, num=n)\n",
    "result_specificity = np.empty((n, n))\n",
    "result_sensitivity = np.empty((n, n))\n",
    "for (i, depth_threshold_q), (j, corr_threshold_q) in product(enumerate(thresh_list), repeat=2):\n",
    "    contingency = strain_scores.assign(corr_hit=lambda x: x.strain_corr_q > corr_threshold_q, depth_hit=lambda x: x.strain_depth_q > depth_threshold_q)[['corr_hit', 'depth_hit']].value_counts().unstack()\n",
    "    # contamination_rate = (contingency.loc[True, False] / contingency.loc[True, True]) / (contingency.loc[False, False] / contingency.loc[False, True]) \n",
    "    a = contingency.loc[True, False] / contingency.loc[True].sum()\n",
    "    b = contingency.loc[False, True] / contingency.loc[:, True].sum()\n",
    "    result_specificity[i, j] = 1 - a * b\n",
    "    result_sensitivity[i, j] = (1 - corr_threshold_q) * (1 - depth_threshold_q)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig, axs = plt.subplots(3, figsize=(7, 15))\n",
    "\n",
    "ax = axs[0]\n",
    "d = pd.DataFrame(result_specificity, index=thresh_list, columns=thresh_list).rename_axis(index='corr_thresh', columns='depth_thresh')\n",
    "cax = make_axes_locatable(ax).append_axes('right', size='5%', pad=0.05)\n",
    "artist = ax.pcolormesh(d.columns, d.index, d, norm=mpl.colors.PowerNorm(1, vmin=0.8, vmax=1))\n",
    "cbar = fig.colorbar(artist, cax=cax)\n",
    "\n",
    "ax = axs[1]\n",
    "d = pd.DataFrame(result_sensitivity, index=thresh_list, columns=thresh_list).rename_axis(index='corr_thresh', columns='depth_thresh')\n",
    "cax = make_axes_locatable(ax).append_axes('right', size='5%', pad=0.05)\n",
    "artist = ax.pcolormesh(d.columns, d.index, d, norm=mpl.colors.PowerNorm(1, vmin=0.8, vmax=1))\n",
    "cbar = fig.colorbar(artist, cax=cax)\n",
    "\n",
    "ax = axs[2]\n",
    "d = pd.DataFrame(sp.stats.hmean(np.stack([result_specificity, result_sensitivity]), axis=0), index=thresh_list, columns=thresh_list).rename_axis(index='corr_thresh', columns='depth_thresh')\n",
    "ax.set_xlabel('corr_thresh')\n",
    "ax.set_ylabel('depth_thresh')\n",
    "cax = make_axes_locatable(ax).append_axes('right', size='5%', pad=0.05)\n",
    "artist = ax.pcolormesh(d.columns, d.index, d, norm=mpl.colors.PowerNorm(1, vmin=0.8, vmax=1))\n",
    "cbar = fig.colorbar(artist, cax=cax)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration: What is a \"reference gene hit\"? (tile depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(orf_x_midas.unstack().astype(float) > bitscore_threshold).T.reindex(idxwhere(strain_scores.tile_depth_q0 > tile_depth_threshold), fill_value=0).sum().value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0] + list(np.logspace(-2, 1, num=100))\n",
    "plt.hist(strain_scores[lambda x: x.species_gene_reference].strain_depth.sort_values(), bins=bins)\n",
    "plt.xscale('symlog', linthresh=1e-4)\n",
    "plt.yscale('log')\n",
    "\n",
    "print(strain_scores[lambda x: x.species_gene_reference].strain_depth.sort_values().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitscore_thresh = 0.95\n",
    "\n",
    "d = pd.DataFrame(dict(\n",
    "    q0=reference_strain_tile_depth_q0.to_series().reindex(strain_corr.index, fill_value=0),\n",
    "    # q1=reference_strain_tile_depth_q1.to_series().reindex(strain_corr.index, fill_value=0),\n",
    "    # q2=reference_strain_tile_depth_q2.to_series().reindex(strain_corr.index, fill_value=0),\n",
    "    # q4=reference_strain_tile_depth_q4.to_series().reindex(strain_corr.index, fill_value=0),\n",
    "    bitscore_ratio=orf_x_midas.unstack(fill_value=0).max()\n",
    "))\n",
    "\n",
    "thresh_list = [0.99, 0.95, 0.8, 0.5, 0.3, 0.1]\n",
    "\n",
    "fig, axs = lib.plot.subplots_grid(ncols=2, naxes=len(thresh_list), ax_width=5, ax_height=3.5, sharex=True, sharey=True)\n",
    "bins = np.logspace(-2, 3, num=50)\n",
    "\n",
    "for thresh, ax in zip(thresh_list, axs.flatten()):\n",
    "# for q, ax in zip(['q2'], axs):\n",
    "    ax.hist('q0', data=d[(d.bitscore_ratio < thresh)], bins=bins, alpha=0.5, label='not-matched')\n",
    "    ax.hist('q0', data=d[(d.bitscore_ratio >= thresh)], bins=bins, alpha=0.5, label='matched')\n",
    "    ax.set_title(f'bitscore_ratio >= {thresh}')\n",
    "# plt.yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.set_xticks(np.logspace(-3, 3, num=7))\n",
    "axs[0,0].legend()\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(orf_x_midas.unstack().astype(float) > 0.95).sum(1).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d = strain_scores.assign(bitscore_ratio_ratio=orf_x_midas.unstack().fillna(0).divide(orf_x_midas.unstack().fillna(0).max(1), axis=0).max())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "plt.scatter('strain_depth', 'tile_depth_q0', data=d, s=1, c='bitscore_ratio', cmap='viridis_r')\n",
    "plt.colorbar()\n",
    "plt.yscale('symlog', linthresh=1e-0)\n",
    "plt.xscale('symlog', linthresh=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_scores[(strain_scores.bitscore_ratio > 0.95)][['bitscore_ratio', 'strain_corr', 'strain_depth', 'species_gene_reference', 'tile_depth_q0', 'gene_length']].sort_values('strain_depth').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = strain_scores.assign(bitscore_ratio_ratio=orf_x_midas.unstack().fillna(0).divide(orf_x_midas.unstack().fillna(0).max(1), axis=0).max())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "plt.scatter('corr_complement', 'tile_depth_q0', data=d, s=1, c='bitscore_ratio', cmap='viridis_r')\n",
    "plt.colorbar()\n",
    "plt.yscale('symlog', linthresh=1e-0)\n",
    "plt.xscale('log')\n",
    "ax.invert_xaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = strain_scores\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.scatter('tile_depth_q0', 'strain_depth', c='strain_corr', data=d[lambda x: x.bitscore_ratio > 0.95], s=1, norm=mpl.colors.PowerNorm(1, vmin=0, vmax=1))\n",
    "plt.colorbar()\n",
    "plt.yscale('symlog', linthresh=1e-2)\n",
    "plt.xscale('symlog', linthresh=1e-2)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.scatter('tile_depth_q0', 'strain_depth', c='strain_corr', data=d[lambda x: x.bitscore_ratio <= 0.95], s=1, norm=mpl.colors.PowerNorm(1, vmin=0, vmax=1))\n",
    "plt.colorbar()\n",
    "plt.yscale('symlog', linthresh=1e-2)\n",
    "plt.xscale('symlog', linthresh=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_inferred_strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_table(path['reference_strain_accuracy'], index_col=0).sort_values('f1', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gene Length Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = strain_scores[lambda x: (x.bitscore_hit) & (x.strain_depth > 0)].join(gene_cluster.centroid_99_length).assign(\n",
    "        log_centroid_99_length=lambda x: np.log10(x.centroid_99_length / 3),\n",
    "        log_strain_depth=lambda x: np.log10(x.strain_depth),\n",
    "    )\n",
    "\n",
    "sns.regplot(\n",
    "    x='log_centroid_99_length',\n",
    "    y='log_strain_depth',\n",
    "    data=d,\n",
    "    lowess=True,\n",
    "    scatter_kws=dict(s=2),\n",
    ")\n",
    "plt.axhline(0, lw=1, linestyle='--', color='k')\n",
    "plt.ylim(-1.5, 1.5)\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = strain_scores[lambda x: (x.bitscore_hit) & (x.strain_depth > 0)].join(gene_cluster.centroid_99_length).assign(\n",
    "        log_centroid_99_length=lambda x: np.log10(x.centroid_99_length / 3),\n",
    "        log_strain_depth=lambda x: np.log10(x.strain_depth),\n",
    "    )\n",
    "\n",
    "sns.regplot(\n",
    "    x='log_centroid_99_length',\n",
    "    y='log_strain_depth',\n",
    "    data=d[d.species_gene_reference],\n",
    "    lowess=True,\n",
    "    scatter_kws=dict(s=2),\n",
    ")\n",
    "plt.axhline(0, lw=1, linestyle='--', color='k')\n",
    "plt.ylim(-1.5, 1.5)\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison to Reference Strains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_geno = sf.Metagenotype.load(path['gtpro_reference_genotype'])\n",
    "strain_geno = sf.Metagenotype.load(f\"data/species/sp-{species}/strain_genomes.gtpro.mgtp.nc\")\n",
    "# ref_hits = (xr.load_dataarray(path['reference_copy_number']) >= 1).to_series().unstack('gene_id').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = sf.Metagenotype.concat(dict(ref=ref_geno, strain=strain_geno), dim='sample')\n",
    "print(m.sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_genome_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.plot_metagenotype(m.sel(position=position_ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmat = m.pdist()\n",
    "_strain = f'strain_{strain_genome_id}'\n",
    "print(dmat[_strain].sort_values().head(10))\n",
    "\n",
    "top_ref_strain = \"UHGG\" + dmat[_strain].sort_values().index[1][len(\"ref_GUT_GENOME\"):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_hits = xr.open_dataarray(path['reference_copy_number']).sel(genome_id=top_ref_strain).to_series() >= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_strain_hits, _ref_hits, _inferred_hits, _depth_hits = align_indexes(\n",
    "    *(\n",
    "        # strain_scores.bitscore_ratio > 0.95,\n",
    "        strain_scores.tile_depth_hit,\n",
    "        ref_hits,\n",
    "        strain_scores.corr_and_depth_hit,\n",
    "        strain_scores.depth_hit,\n",
    "    ),\n",
    "    how='outer',\n",
    ")\n",
    "d0 = pd.DataFrame(dict(strain=_strain_hits, ref=_ref_hits, inf=_inferred_hits, depth=_depth_hits))\n",
    "d1 = d0.value_counts().sort_index()\n",
    "d1.unstack('strain', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(x='strain', y='tile_depth_q0', hue='ref', data=strain_scores.join(d0), dodge=True, s=1, alpha=0.2)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_geno.to_estimated_genotype().cdist(ref_geno.to_estimated_genotype()).iloc[0].sort_values().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_inferred_strain_sample_list = idxwhere(fit.community.data.sel(strain=top_inferred_strain).to_series() > 0.95)\n",
    "allele_sorted_positions = fit.genotype.data.sel(strain=top_inferred_strain).to_series().sort_values().index\n",
    "\n",
    "sf.plot_metagenotype(fit.metagenotype.sel(sample=top_inferred_strain_sample_list, position=allele_sorted_positions), row_cluster=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey Across xjin Species"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "m = fit.sel(sample=idxwhere(fit.community.data.sel(strain=top_inferred_strain).to_series() > 0.95)).metagenotype.data.sum(\"sample\")\n",
    "total_counts = m.sum(\"allele\")\n",
    "x = sf.math.binary_entropy((m / total_counts).values).T\n",
    "total_weight = total_counts.values.sum()\n",
    "(x * total_counts.values).sum() / total_counts.values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_strains = pd.read_table('meta/genome.tsv', index_col='genome_id')[lambda x: ~x.genome_path.isna()]\n",
    "\n",
    "species_strain_counts = ref_strains.value_counts('species_id')\n",
    "\n",
    "_all_species_depth = species_depth\n",
    "\n",
    "\n",
    "all_species_strain_accuracy = {}\n",
    "for _species in tqdm(species_strain_counts.index):\n",
    "    _strain = idxwhere(ref_strains.species_id == _species)[0]\n",
    "\n",
    "    # Format paths to reflect _species.\n",
    "    _path_params = path_params.copy()\n",
    "    _path_params.update(species=_species, strain_genome_id=_strain)\n",
    "    _path = {k: path_patterns[k].format(**_path_params) for k in path_patterns}\n",
    "    \n",
    "    # Check how many strains.\n",
    "    _count = species_strain_counts[_species]\n",
    "    if _count > 1:\n",
    "        print(f\"Species {_species} has {_count} strains.\")\n",
    "        continue\n",
    "        \n",
    "    # Some species missing from _all_species_depth.\n",
    "    # FIXME: This doesn't make sense with the reindexing of _species_depth below...?\n",
    "    if _species in _all_species_depth:\n",
    "        _species_depth = _all_species_depth[_species]\n",
    "    else:\n",
    "        _species_depth = np.nan\n",
    "    \n",
    "    if not os.path.exists(_path['flag']):\n",
    "        print(f\"{_species} is missing flag file\")\n",
    "        continue\n",
    "    if not os.path.exists(_path[\"fit\"]):\n",
    "        print(f\"{_species} is missing fit file\")\n",
    "        continue\n",
    "    if not os.path.exists(_path['reference_strain_accuracy']):\n",
    "        print(f\"{_species} is missing accuracy file\")\n",
    "        continue\n",
    "    _species_gene_list = pd.read_table(_path[\"species_gene_reference\"], names=['gene_id']).gene_id.tolist()\n",
    "    _fit = sf.World.load(_path[\"fit\"])\n",
    "    _thresh = pd.read_table(_path[\"strain_thresholds\"], index_col='strain')\n",
    "    _accuracy = pd.read_table(_path['reference_strain_accuracy'], index_col='strain')\n",
    "    _accuracy_depth_only = pd.read_table(_path['reference_strain_accuracy_depth_only'], index_col='strain')\n",
    "    _top_strain = _fit.community.sel(sample=idxwhere(_fit.community.sample.to_series().str.startswith('xjin_'))).mean(\"sample\").to_series().idxmax()\n",
    "    if not _top_strain in _accuracy.index:\n",
    "        print(f\"{_species} {_strain} is missing accuracy info\")\n",
    "        continue\n",
    "    with open(_path[\"species_free_samples\"]) as f:\n",
    "        _species_free_samples = [line.strip() for line in f]\n",
    "    _sample_to_strain = pd.read_table(_path[\"strain_samples\"], index_col=['sample']).strain\n",
    "    _sample_list = idxwhere(_sample_to_strain == _top_strain)\n",
    "    \n",
    "    _accuracy = _accuracy.join(_accuracy_depth_only, rsuffix='_depth_only').loc[_top_strain]\n",
    "    _accuracy['geno_entropy'] = _fit.genotype.entropy().to_series()[_top_strain]\n",
    "    _accuracy['num_strain_samples'] = len(_sample_list)\n",
    "    _accuracy['num_species_free_samples'] = len(_species_free_samples)\n",
    "    _accuracy['num_hmp_samples'] = sum([not s.startswith('xjin_') for s in _sample_list])\n",
    "    _accuracy['num_species_genes'] = len(_species_gene_list)\n",
    "    _accuracy['depth_stdev'] = _species_depth.reindex(_sample_list, fill_value=0).std()\n",
    "    _accuracy['depth_max'] = _species_depth.reindex(_sample_list, fill_value=0).max()\n",
    "    _accuracy['depth_sum'] = _species_depth.reindex(_sample_list, fill_value=0).sum()\n",
    "    try:\n",
    "        _accuracy['corr_thresh'] = _thresh.loc[_top_strain].correlation\n",
    "        _accuracy['depth_thresh'] = _thresh.loc[_top_strain].depth_low\n",
    "    except KeyError as err:  # FIXME: This should next happen\n",
    "        _accuracy['corr_thresh'] = np.nan\n",
    "        _accuracy['depth_thresh'] = np.nan\n",
    "        print(err)\n",
    "    all_species_strain_accuracy[_species] = _accuracy\n",
    "    \n",
    "all_species_strain_accuracy = (\n",
    "    pd.DataFrame(all_species_strain_accuracy).T\n",
    "    # .rename(columns=dict(\n",
    "    #     precision_depth_only_1to1='precision_1to1_depth_only',\n",
    "    #     recall_depth_only_1to1='recall_1to1_depth_only',\n",
    "    #     f1_depth_only_1to1='f1_1to1_depth_only',\n",
    "    # ))\n",
    "    .assign(\n",
    "        power_index=lambda x: (x.depth_stdev * np.sqrt(x.num_strain_samples)).fillna(0)\n",
    "    )\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path['flag']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "all_species_strain_accuracy.drop(columns=['precision_depth_only',\n",
    "       'recall_depth_only', 'f1_depth_only', 'precision_1to1', 'recall_1to1',\n",
    "       'f1_1to1', 'precision_1to1_depth_only', 'recall_1to1_depth_only',\n",
    "       'f1_1to1_depth_only'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = all_species_strain_accuracy\n",
    "fig, axs = plt.subplots(4, 3, figsize=(14, 20), sharex=True, sharey=True)\n",
    "\n",
    "span = [5e-2, 1 - 1e-3]\n",
    "span = [0, 1]\n",
    "\n",
    "for row, c in zip(axs, ['depth_sum', 'geno_entropy', 'power_index', 'corr_thresh']):\n",
    "    row[0].set_ylabel(f'depth+corr ({c})')\n",
    "    for ax, _score in zip(row, ['precision', 'recall', 'f1']):\n",
    "        ax.scatter(f'{_score}_depth_only', f'{_score}', s=20, c=c, norm=mpl.colors.PowerNorm(1/3), data=d)\n",
    "        ax.plot(span, span)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.set_title(_score)\n",
    "    \n",
    "# ax.set_yscale('logit')\n",
    "# ax.set_xscale('logit')\n",
    "ax.set_xlim(*span)\n",
    "ax.set_ylim(*span)\n",
    "axs[-1, 0].set_xlabel('depth only')\n",
    "# axs[-1, 0].set_ylabel('depth+corr')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter('depth_sum', 'geno_entropy', c='f1', data=all_species_strain_accuracy)\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter('depth_sum', 'f1', c='geno_entropy', data=all_species_strain_accuracy)\n",
    "plt.xscale('log')\n",
    "plt.xticks([0.001, 0.01, 0.1, 1, 10, 100, 1_000, 10_000, 100_000])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    sp.stats.spearmanr(all_species_strain_accuracy['depth_max'], all_species_strain_accuracy['f1']),\n",
    "    sp.stats.spearmanr(all_species_strain_accuracy['depth_sum'], all_species_strain_accuracy['f1']),\n",
    "    sp.stats.spearmanr(all_species_strain_accuracy['depth_stdev'], all_species_strain_accuracy['f1']),\n",
    "    sp.stats.spearmanr(all_species_strain_accuracy['power_index'], all_species_strain_accuracy['f1']),\n",
    "    sp.stats.spearmanr(all_species_strain_accuracy['num_strain_samples'], all_species_strain_accuracy['f1']),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter('depth_max', 'f1', c='geno_entropy', data=all_species_strain_accuracy)\n",
    "plt.xscale('log')\n",
    "plt.xticks([0.01, 0.1, 1, 10, 100, 1_000, 10_000])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_species_strain_accuracy.sort_values('f1', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter('depth_max', 'f1', data=all_species_strain_accuracy, lw=1, edgecolor='k', s=40, vmin=0.5, vmax=1)\n",
    "plt.ylim(0.4, 1.02)\n",
    "# plt.xlim(0.4, 1.02)\n",
    "plt.colorbar()\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter('precision_depth_only', 'recall_depth_only', data=all_species_strain_accuracy, c='f1', lw=1, edgecolor='k', s=40, vmin=0.5, vmax=1)\n",
    "plt.ylim(0, 1.02)\n",
    "plt.xlim(0, 1.02)\n",
    "plt.colorbar()\n",
    "# plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter('precision', 'recall', data=all_species_strain_accuracy)\n",
    "plt.scatter('precision_depth_only', 'recall_depth_only', data=all_species_strain_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(all_species_strain_accuracy.f1, bins=np.linspace(0, 1, num=40))\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_strains = pd.read_table('meta/genome.tsv', index_col='genome_id')[lambda x: ~x.genome_path.isna()]\n",
    "species_strain_counts = ref_strains.value_counts('species_id')\n",
    "_all_species_depth = species_depth\n",
    "\n",
    "\n",
    "xjin_benchmarking = []\n",
    "for _species in tqdm(species_strain_counts.index):\n",
    "    # Format paths to reflect _species.\n",
    "    _path_params = path_params.copy()\n",
    "    _path_params.update(species=_species)\n",
    "    _path = {k: path_patterns[k].format(**_path_params) for k in path_patterns}\n",
    "    \n",
    "    if not os.path.exists(_path['xjin_benchmarking']):\n",
    "        print(_path[\"xjin_benchmarking\"])\n",
    "        continue\n",
    "\n",
    "    xjin_benchmarking.append(pd.read_table(_path[\"xjin_benchmarking\"]).assign(species=_species))\n",
    "\n",
    "xjin_benchmarking = pd.concat(xjin_benchmarking).assign(\n",
    "    # Reasonable filters:\n",
    "    to_drop=lambda x: ( False\n",
    "        | (x.num_reference_genomes > 1)\n",
    "        | (x.num_strain_samples != 10)  # FIXME\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xjin_benchmarking[~xjin_benchmarking.to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfacts",
   "language": "python",
   "name": "sfacts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}