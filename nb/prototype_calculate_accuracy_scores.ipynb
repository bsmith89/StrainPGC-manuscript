{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as _os\n",
    "_os.chdir(_os.environ['PROJECT_ROOT'])\n",
    "_os.path.realpath(_os.path.curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "from lib.pandas_util import idxwhere, align_indexes, invert_mapping\n",
    "import matplotlib as mpl\n",
    "import lib.plot\n",
    "import statsmodels as sm\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "from tempfile import mkstemp\n",
    "import time\n",
    "import subprocess\n",
    "from itertools import chain\n",
    "import os\n",
    "from itertools import product\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sfacts as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.thisproject.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "plt.rcParams['figure.dpi'] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_subset = 'xjin'\n",
    "group = 'xjin_hmp2'\n",
    "stemA = 'r.proc'\n",
    "\n",
    "path = {}\n",
    "\n",
    "path.update(dict(\n",
    "    species_taxonomy=\"ref/gtpro/species_taxonomy_ext.tsv\",\n",
    "    all_species_depth_subset=f\"data/group/{group_subset}/{stemA}.gtpro.species_depth.tsv\",\n",
    "    all_species_depth=f\"data/group/{group}/{stemA}.gtpro.species_depth.tsv\",\n",
    "    midasdb_genomes=\"ref/uhgg_genomes_all_4644.tsv\",\n",
    "    strain_genomes=\"meta/genome.tsv\",\n",
    "))\n",
    "\n",
    "path_exists = {}\n",
    "for p in path:\n",
    "    path_exists[path[p]] = os.path.exists(path[p])\n",
    "\n",
    "assert all(path_exists.values()), '\\n'.join([\"Missing files:\"] + [p for p in path_exists if not path_exists[p]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_depth = lib.thisproject.data.load_species_depth(path['all_species_depth'])\n",
    "species_depth_subset = lib.thisproject.data.load_species_depth(path['all_species_depth_subset'])\n",
    "rabund = species_depth.apply(lambda x: x / x.sum(), axis=1)\n",
    "rabund_subset = species_depth_subset.apply(lambda x: x / x.sum(), axis=1)\n",
    "\n",
    "n_species = 40\n",
    "top_species = (rabund_subset > 1e-5).sum().sort_values(ascending=False).head(n_species).index\n",
    "\n",
    "fig, axs = plt.subplots(n_species, figsize=(10, 0.5 * n_species), sharex=True, sharey=True)\n",
    "\n",
    "bins = np.logspace(-7, 0, num=51)\n",
    "\n",
    "for species_id, ax in zip(top_species, axs):\n",
    "    ax.hist(rabund_subset[species_id], bins=bins, alpha=0.7)\n",
    "    ax.hist(rabund[species_id], bins=bins, alpha=0.7)\n",
    "    ax.set_xscale('log')\n",
    "    prevalence = (rabund_subset[species_id] > 1e-5).mean()\n",
    "    ax.set_title(\"\")\n",
    "    # ax.set_xticks()\n",
    "    # ax.set_yticks()\n",
    "    ax.yaxis.set_visible(False)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.patch.set_alpha(0.0)\n",
    "    for spine in ['left', 'right', 'top', 'bottom']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "    ax.annotate(f'{species_id} ({prevalence:0.0%})', xy=(0.05, 0.1), ha='left', xycoords=\"axes fraction\")\n",
    "    ax.set_xlim(left=1e-7)\n",
    "    ax.set_ylim(top=300)\n",
    "    \n",
    "ax.xaxis.set_visible(True)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "\n",
    "fig.subplots_adjust(hspace=-0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_species = 40\n",
    "top_species = (species_depth_subset > 1e-3).sum().sort_values(ascending=False).head(n_species).index\n",
    "\n",
    "fig, axs = plt.subplots(n_species, figsize=(10, 0.5 * n_species), sharex=True, sharey=True)\n",
    "\n",
    "bins = np.logspace(-3, 4, num=51)\n",
    "\n",
    "for species_id, ax in zip(top_species, axs):\n",
    "    ax.hist(species_depth_subset[species_id], bins=bins, alpha=0.7)\n",
    "    ax.hist(species_depth[species_id], bins=bins, alpha=0.7)\n",
    "    ax.set_xscale('log')\n",
    "    prevalence = (species_depth_subset[species_id] > 1e-5).mean()\n",
    "    ax.set_title(\"\")\n",
    "    # ax.set_xticks()\n",
    "    # ax.set_yticks()\n",
    "    ax.yaxis.set_visible(False)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.patch.set_alpha(0.0)\n",
    "    for spine in ['left', 'right', 'top', 'bottom']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "    ax.annotate(f'{species_id} ({prevalence:0.0%})', xy=(0.05, 0.1), ha='left', xycoords=\"axes fraction\")\n",
    "    ax.set_xlim(left=1e-4)\n",
    "    ax.set_ylim(top=300)\n",
    "    \n",
    "ax.xaxis.set_visible(True)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "\n",
    "fig.subplots_adjust(hspace=-0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_depth = lib.thisproject.data.load_species_depth(path['all_species_depth'])\n",
    "species_depth_subset = lib.thisproject.data.load_species_depth(path['all_species_depth_subset'])\n",
    "rabund = species_depth.apply(lambda x: x / x.sum(), axis=1)\n",
    "rabund_subset = species_depth_subset.apply(lambda x: x / x.sum(), axis=1)\n",
    "\n",
    "n_species = 40\n",
    "second_species = (rabund_subset > 1e-5).sum().sort_values(ascending=False).head(n_species * 2).tail(n_species).index\n",
    "\n",
    "fig, axs = plt.subplots(n_species, figsize=(10, 0.5 * n_species), sharex=True, sharey=True)\n",
    "\n",
    "bins = np.logspace(-7, 0, num=51)\n",
    "\n",
    "for species_id, ax in zip(second_species, axs):\n",
    "    ax.hist(rabund_subset[species_id], bins=bins, alpha=0.7)\n",
    "    ax.hist(rabund[species_id], bins=bins, alpha=0.7)\n",
    "    ax.set_xscale('log')\n",
    "    prevalence = (rabund_subset[species_id] > 1e-5).mean()\n",
    "    ax.set_title(\"\")\n",
    "    # ax.set_xticks()\n",
    "    # ax.set_yticks()\n",
    "    ax.yaxis.set_visible(False)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.patch.set_alpha(0.0)\n",
    "    for spine in ['left', 'right', 'top', 'bottom']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "    ax.annotate(f'{species_id} ({prevalence:0.0%})', xy=(0.05, 0.1), ha='left', xycoords=\"axes fraction\")\n",
    "    ax.set_xlim(left=1e-7)\n",
    "    ax.set_ylim(top=300)\n",
    "    \n",
    "ax.xaxis.set_visible(True)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "\n",
    "fig.subplots_adjust(hspace=-0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_species = 40\n",
    "second_species = (species_depth_subset > 1e-3).sum().sort_values(ascending=False).head(n_species * 2).tail(n_species).index\n",
    "\n",
    "fig, axs = plt.subplots(n_species, figsize=(10, 0.5 * n_species), sharex=True, sharey=True)\n",
    "\n",
    "bins = np.logspace(-3, 4, num=51)\n",
    "\n",
    "for species_id, ax in zip(second_species, axs):\n",
    "    ax.hist(species_depth_subset[species_id], bins=bins, alpha=0.7)\n",
    "    ax.hist(species_depth[species_id], bins=bins, alpha=0.7)\n",
    "    ax.set_xscale('log')\n",
    "    prevalence = (species_depth_subset[species_id] > 1e-5).mean()\n",
    "    ax.set_title(\"\")\n",
    "    # ax.set_xticks()\n",
    "    # ax.set_yticks()\n",
    "    ax.yaxis.set_visible(False)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.patch.set_alpha(0.0)\n",
    "    for spine in ['left', 'right', 'top', 'bottom']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "    ax.annotate(f'{species_id} ({prevalence:0.0%})', xy=(0.05, 0.1), ha='left', xycoords=\"axes fraction\")\n",
    "    ax.set_xlim(left=1e-4)\n",
    "    ax.set_ylim(top=300)\n",
    "    \n",
    "ax.xaxis.set_visible(True)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "\n",
    "fig.subplots_adjust(hspace=-0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(species_depth_subset, norm=mpl.colors.PowerNorm(1/5), metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_depth_corr = pd.DataFrame(sp.spatial.distance.squareform(sp.spatial.distance.pdist(species_depth_subset.T, metric='cosine')), index=species_depth_subset.columns, columns=species_depth_subset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(1 - species_depth_corr, figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for species in sorted(top_species):\n",
    "    print(f'xjin_{species}_a', species, species_taxonomy.loc[species].g__, species_taxonomy.loc[species].s__, '', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = '101306'\n",
    "\n",
    "species_taxonomy = lib.thisproject.data.load_species_taxonomy(path[\"species_taxonomy\"])\n",
    "species_taxonomy.loc[species]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_genome = pd.read_table(path[\"strain_genomes\"], dtype='str')\n",
    "strain_genome[strain_genome.species_id == species]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_genome_ids = strain_genome[strain_genome.species_id == species].genome_id\n",
    "print(strain_genome_ids)\n",
    "strain_genome_id = strain_genome_ids.tolist()[0]\n",
    "assert strain_genome_ids.shape[0] == 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# FIXME: Hard-coded because the cell above doesn't account for multiple strains\n",
    "strain_genome_id = 'xjin_100196_vpi5482'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid = 75\n",
    "\n",
    "path.update(dict(\n",
    "    # uhgg_x_strain=f'data/species/sp-{species}/genome/midas_uhgg_pangenome.{strain_genome_id}-blastp.tsv',\n",
    "    # strain_x_uhgg=f'data/species/sp-{species}/genome/{strain_genome_id}.midas_uhgg_pangenome-blastn.tsv',\n",
    "    # strain_x_strain=f'data/species/sp-{species}/genome/{strain_genome_id}.{strain_genome_id}-blastn.tsv',\n",
    "    strain_cds_length=f'data/species/sp-{species}/genome/{strain_genome_id}.prodigal-single.cds.nlength.tsv',\n",
    "    strain_x_uhgg_bitscore_ratio=f'data/species/sp-{species}/genome/{strain_genome_id}.midas_uhgg_pangenome-blastn.bitscore_ratio-c{centroid}.tsv',\n",
    "))\n",
    "\n",
    "path_exists = {}\n",
    "for p in path:\n",
    "    path_exists[path[p]] = os.path.exists(path[p])\n",
    "\n",
    "assert all(path_exists.values()), '\\n'.join([\"Missing files:\"] + [p for p in path_exists if not path_exists[p]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default file path forming for interactive use.\n",
    "\n",
    "stemB = 'filt-poly05-cvrg05.ss-g10000-block0-seed0.fit-sfacts37-s85-seed0'\n",
    "stemC = 'sfacts42-seed0'\n",
    "spgc_params = 'corr10-depth10'\n",
    "\n",
    "path.update(dict(\n",
    "    flag=f\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.{stemB}.refit-{stemC}.gene{centroid}.spgc-{spgc_params}.strain_files.flag\",\n",
    "    fit=f\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.{stemB}.world.nc\",\n",
    "    refit=f\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.{stemB}.refit-{stemC}.world.nc\",\n",
    "    strain_correlation=f\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.{stemB}.gene{centroid}.spgc.strain_correlation.tsv\",\n",
    "    strain_depth_ratio=f\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.{stemB}.gene{centroid}.spgc.strain_depth_ratio.tsv\",\n",
    "    strain_fraction=f\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.{stemB}.comm.tsv\",\n",
    "    species_gene_mean_depth=f\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.gene{centroid}.spgc.species_depth.tsv\",\n",
    "    species_gtpro_depth=f\"data/group/{group}/{stemA}.gtpro.species_depth.tsv\",\n",
    "    species_correlation=f\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.gene{centroid}.spgc.species_correlation.tsv\",\n",
    "    species_gene_denovo=f\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.gene{centroid}.spgc.species_gene.list\",\n",
    "    species_gene_reference=f\"data/species/sp-{species}/midasuhgg.pangenome.gene{centroid}.species_gene-trim25-prev95.list\",\n",
    "    strain_thresholds=f\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.{stemB}.gene{centroid}.spgc-{spgc_params}.strain_gene_threshold.tsv\",\n",
    "    strain_corr_quantile=f\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.{stemB}.gene{centroid}.spgc.strain_corr_quantile.tsv\",\n",
    "    strain_depth_quantile=f\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.{stemB}.gene{centroid}.spgc.strain_depth_quantile.tsv\",\n",
    "    gene_annotations=f\"ref/midasdb_uhgg_gene_annotations/sp-{species}.gene{centroid}_annotations.tsv\",\n",
    "    # raw_gene_depth=f\"data/group/{group}/species/sp-{species}/{stemA}.pangenome95.gene{centroid}_depth.nc\",\n",
    "    norm_gene_depth=f\"data/group/{group}/species/sp-{species}/{stemA}.gene99-agg{centroid}.normed_depth2.nc\",\n",
    "    raw_gene_depth=f\"data/group/{group}/species/sp-{species}/{stemA}.gene99-agg{centroid}.depth2.nc\",\n",
    "    # raw_gene_depth=f\"data/group/{group}/species/sp-{species}/{stemA}.gene{centroid}.normed_depth2.nc\",\n",
    "    # reference_copy_number=f\"ref/midasdb_uhgg_pangenomes/{species}/gene{centroid}.reference_copy_number.nc\",\n",
    "    cluster_info=f\"ref/midasdb_uhgg/pangenomes/{species}/cluster_info.txt\",\n",
    "    gtpro_reference_genotype=f\"data/species/sp-{species}/gtpro_ref.mgtp.nc\",\n",
    "    reference_strain_accuracy=f\"data/group/xjin_hmp2/species/sp-{species}/{stemA}.gtpro.{stemB}.gene{centroid}.spgc.{strain_genome_id}.gene_content_reconstruction_accuracy.tsv\",\n",
    "))\n",
    "path_exists = {}\n",
    "for p in path:\n",
    "    path_exists[path[p]] = os.path.exists(path[p])\n",
    "\n",
    "assert all(path_exists.values()), '\\n'.join([\"Missing files:\"] + [p for p in path_exists if not path_exists[p]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path['flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = sf.World.load(path['fit'])\n",
    "print(fit.sizes)\n",
    "np.random.seed(0)\n",
    "position_ss = fit.random_sample(position=min(fit.sizes['position'], 500)).position\n",
    "\n",
    "\n",
    "fit_subset = fit.sel(sample=list(set(species_depth_subset.index) & set(fit.sample.values)))\n",
    "\n",
    "fuzzy_geno = sf.Genotype.load(path['fit'])  # FIXME: refit\n",
    "fuzzy_geno = sf.World.from_combined(fuzzy_geno, fit.metagenotype, fit.community)\n",
    "\n",
    "sf.evaluation.metagenotype_error2(fit)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.plot.plot_metagenotype(\n",
    "    (\n",
    "        fit\n",
    "        .drop_low_abundance_strains(0.05)\n",
    "        .sel(position=position_ss)\n",
    "    ),\n",
    "    # scaley=0.2,\n",
    "    # scalex=0.3,\n",
    "    row_linkage_func=lambda w: w.metagenotype.linkage(\"position\"),\n",
    "    col_linkage_func=lambda w: w.metagenotype.linkage(\"sample\"),\n",
    ")\n",
    "# sf.plot.plot_depth(\n",
    "#     fit.sel(position=position_ss),\n",
    "#     # scaley=0.2, scalex=0.3,\n",
    "#     row_linkage_func=lambda w: w.metagenotype.linkage(\"position\"),\n",
    "#     col_linkage_func=lambda w: w.community.linkage(),\n",
    "# )\n",
    "# sf.plot.plot_dominance(\n",
    "#     fit.sel(position=position_ss),\n",
    "#     # scaley=0.2, scalex=0.3,\n",
    "#     row_linkage_func=lambda w: w.metagenotype.linkage(\"position\"),\n",
    "#     col_linkage_func=lambda w: w.community.linkage(),\n",
    "# )\n",
    "sf.plot.plot_community(\n",
    "    (\n",
    "        fit\n",
    "        .drop_low_abundance_strains(0.05)\n",
    "        .sel(position=position_ss)\n",
    "    ),\n",
    "    scaley=0.3,\n",
    "    # scalex=0.3,\n",
    "    col_linkage_func=lambda w: w.metagenotype.linkage(\"sample\"),\n",
    "    row_linkage_func=lambda w: fuzzy_geno.drop_low_abundance_strains(0.05).genotype.linkage(\"strain\"),\n",
    ")\n",
    "sf.plot.plot_genotype(\n",
    "    (\n",
    "        fit\n",
    "        .drop_low_abundance_strains(0.05)\n",
    "        .sel(position=position_ss)\n",
    "    ),\n",
    "    scaley=0.2,\n",
    "    # scalex=0.3,\n",
    "    col_linkage_func=lambda w: w.metagenotype.linkage(\"position\"),\n",
    "    row_linkage_func=lambda w: fuzzy_geno.drop_low_abundance_strains(0.05).genotype.linkage(\"strain\"),\n",
    ")\n",
    "\n",
    "sf.plot.plot_genotype(\n",
    "    (\n",
    "        fuzzy_geno\n",
    "        .drop_low_abundance_strains(0.05)\n",
    "        .sel(position=position_ss)\n",
    "    ),\n",
    "    scaley=0.2,\n",
    "    # scalex=0.3,\n",
    "    col_linkage_func=lambda w: w.metagenotype.linkage(\"position\"),\n",
    "    row_linkage_func=lambda w: fuzzy_geno.drop_low_abundance_strains(0.05).genotype.linkage(\"strain\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fit_subset.community.mean(\"sample\").to_series().sort_values(ascending=False).head(5))\n",
    "top_inferred_strain = fit_subset.community.mean(\"sample\").to_series().idxmax()\n",
    "\n",
    "assert fit_subset.community.mean(\"sample\").sel(strain=top_inferred_strain) > 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_table(path['reference_strain_accuracy'], index_col=0).sort_values('f1', ascending=False).loc[[top_inferred_strain]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# FIXME: Hard-coded because the cell above doesn't account for multiple strains\n",
    "top_inferred_strain = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_cluster = pd.read_table(\n",
    "    path[\"cluster_info\"]\n",
    ").set_index('centroid_99', drop=False).rename_axis(index='gene_id')\n",
    "gene_annotation = pd.read_table(\n",
    "    path[\"gene_annotations\"],\n",
    "    names=['locus_tag', 'ftype', 'length_bp', 'gene', 'EC_number', 'COG', 'product'],\n",
    "    index_col='locus_tag',\n",
    ").rename(columns=str.lower)\n",
    "\n",
    "gene_meta = gene_cluster.loc[gene_cluster[f'centroid_{centroid}'].unique()].join(gene_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blastp_header_names = [\n",
    "    'qseqid',\n",
    "    'sseqid',\n",
    "    'pident',\n",
    "    'length',\n",
    "    'mismatch',\n",
    "    'gapopen',\n",
    "    'qstart',\n",
    "    'qend',\n",
    "    'sstart',\n",
    "    'send',\n",
    "    'evalue',\n",
    "    'bitscore'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orf_length = pd.read_table(path['strain_cds_length'], names=['orf', 'length'], index_col=['orf']).squeeze()\n",
    "\n",
    "orf_x_midas = pd.read_table(path['strain_x_uhgg_bitscore_ratio'], index_col=['orf', 'gene']).squeeze()\n",
    "\n",
    "\n",
    "# _strain_x_strain = (\n",
    "#     pd.read_table(\n",
    "#         path['strain_x_strain'],\n",
    "#         names=blastp_header_names\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# _max_bitscore = _strain_x_strain.groupby(['qseqid']).bitscore.max()\n",
    "\n",
    "# strain_x_uhgg = (\n",
    "#     pd.read_table(\n",
    "#         path['strain_x_uhgg'],\n",
    "#         names=blastp_header_names\n",
    "#     )\n",
    "#     .assign(bitscore_ratio=lambda x: x.bitscore / x.qseqid.map(_max_bitscore))\n",
    "#     .assign(sseq_centroid=lambda x: x.sseqid.map(gene_cluster[f'centroid_{centroid}']))\n",
    "# )\n",
    "\n",
    "# best_uhgg_hit = strain_x_uhgg.groupby('qseqid').apply(lambda d: d.sort_values('bitscore').iloc[-1]).groupby('sseq_centroid').bitscore_ratio.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orf_x_midas = strain_x_uhgg.groupby(['qseqid', 'sseq_centroid']).bitscore_ratio.max()\n",
    "\n",
    "\n",
    "bins = np.linspace(0, 1)\n",
    "plt.hist(orf_x_midas.unstack(fill_value=0).max(0), bins=bins, density=True)\n",
    "plt.hist(orf_x_midas.unstack(fill_value=0).max(1), bins=bins, density=True, alpha=0.5)\n",
    "plt.yscale('log')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(orf_x_midas.unstack().astype(float) > 0.5).sum(1).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.hist(best_uhgg_hit, alpha=0.5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.scatter('pident', 'bitscore_ratio', data=strain_x_uhgg, s=1)\n",
    "plt.plot([0, 100], [0, 1], color='k', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_corr = pd.read_table(path[\"strain_correlation\"], index_col=['gene_id', 'strain']).squeeze().unstack('strain', fill_value=0)\n",
    "strain_depth = pd.read_table(\n",
    "    path[\"strain_depth_ratio\"],\n",
    "    index_col=['gene_id', 'strain']\n",
    ").squeeze().unstack()\n",
    "# strain_corr, strain_depth = align_indexes(*align_indexes(strain_corr, strain_depth), axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_corr_q = pd.read_table(path['strain_corr_quantile'], index_col=['gene_id'])\n",
    "strain_corr_q.columns = strain_corr_q.columns.astype(int)\n",
    "strain_depth_q = pd.read_table(path['strain_depth_quantile'], index_col=['gene_id'])\n",
    "strain_depth_q.columns = strain_depth_q.columns.astype(int)\n",
    "\n",
    "bins = np.logspace(-4, 0)\n",
    "plt.hist(strain_corr_q[top_inferred_strain], bins=bins, cumulative=-1, alpha=0.5)\n",
    "plt.hist(strain_depth_q[top_inferred_strain], bins=bins, cumulative=-1, alpha=0.5)\n",
    "plt.xscale('log')\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_thresholds = (\n",
    "    pd.read_table(path[\"strain_thresholds\"], index_col='strain')\n",
    "    .rename(columns=dict(\n",
    "        # correlation_strict='corr_threshold_strict',\n",
    "        correlation='corr_threshold',\n",
    "        # correlation_lenient='corr_threshold_lenient',\n",
    "        depth_high='depth_thresh_high',\n",
    "        depth_low='depth_thresh_low',\n",
    "    ))\n",
    ")\n",
    "\n",
    "_strain_meta = (\n",
    "    strain_thresholds\n",
    "    .join(fuzzy_geno.genotype.entropy().to_series().rename('genotype_entropy'))\n",
    "    # .join(refit.genotype.entropy().to_series().rename('genotype_refit_entropy'))\n",
    "    # .join(fit.metagenotype.entropy().to_series().rename('metagenotype_entropy').groupby(sample_to_strain).mean().rename(int))\n",
    "    # .join(strain_to_sample_list.apply(len).rename('num_samples'))\n",
    "    # .join(species_depth.apply(lambda x: x**(1)).groupby(sample_to_strain).std().rename('depth_stdev').rename(int))\n",
    "    # .join(species_depth.apply(lambda x: x**(1)).groupby(sample_to_strain).max().rename('depth_max').rename(int))\n",
    "    # .join(species_depth.apply(lambda x: x**(1)).groupby(sample_to_strain).sum().rename('depth_sum').rename(int))\n",
    "    # .assign(power_index=lambda x: (x.depth_stdev * np.sqrt(x.num_samples)).fillna(0))\n",
    ")\n",
    "strain_meta = _strain_meta\n",
    "\n",
    "\n",
    "# power_index_thresh = 5\n",
    "# genotype_entropy_thresh = 0.2\n",
    "# genotype_refit_entropy_thresh = 1.0\n",
    "\n",
    "# high_power_strain_list = idxwhere(\n",
    "#     (strain_meta.power_index > power_index_thresh)\n",
    "#     & (strain_meta.genotype_entropy < genotype_entropy_thresh)\n",
    "#     & (strain_meta.genotype_refit_entropy < genotype_refit_entropy_thresh)\n",
    "# )\n",
    "# print(len(high_power_strain_list))\n",
    "# highest_power_strain_list = strain_meta.sort_values('power_index', ascending=False).head(3).index\n",
    "\n",
    "# plt.scatter(strain_meta.power_index, strain_meta.corr_threshold, c=strain_meta.genotype_refit_entropy, alpha=0.5)\n",
    "# plt.axvline(power_index_thresh, lw=1, linestyle='--', color='k')\n",
    "# plt.colorbar()\n",
    "# plt.xscale('log')\n",
    "\n",
    "strain_meta.loc[[top_inferred_strain]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_corr = pd.read_table(path[\"species_correlation\"], names=['sample', 'correlation'], index_col='sample').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path[\"species_gene_denovo\"]) as f:\n",
    "    species_gene_denovo_hit = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path[\"species_gene_reference\"]) as f:\n",
    "    species_gene_reference_hit = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_threshold = strain_meta.depth_thresh_low.loc[top_inferred_strain]\n",
    "corr_threshold = strain_meta.corr_threshold.loc[top_inferred_strain]\n",
    "# corr_threshold = 0.95  # Set manually, but this could/should be the automatically selected threshold.\n",
    "# depth_threshold = 0.2  # Set manually, but this could/should be the automatically selected threshold.\n",
    "bitscore_threshold = 0.5\n",
    "\n",
    "strain_scores = (\n",
    "    pd.DataFrame(dict(\n",
    "        bitscore_ratio=orf_x_midas.unstack(fill_value=0).max(),\n",
    "        strain_corr=strain_corr[top_inferred_strain],\n",
    "        strain_depth=strain_depth[top_inferred_strain],\n",
    "        species_corr=species_corr,\n",
    "        strain_corr_q=strain_corr_q[top_inferred_strain],\n",
    "        strain_depth_q=strain_depth_q[top_inferred_strain],\n",
    "    ))\n",
    "    .fillna(0)\n",
    "    .assign(\n",
    "        bitscore_hit=lambda x: x.bitscore_ratio > bitscore_threshold,\n",
    "        not_bitscore_hit=lambda x: x.bitscore_ratio < bitscore_threshold,\n",
    "        corr_and_depth_hit=lambda x: (x.strain_corr > corr_threshold) & (x.strain_depth > depth_threshold),\n",
    "        species_gene_denovo=lambda x: x.index.to_series().isin(species_gene_denovo_hit),\n",
    "        species_gene_reference=lambda x: x.index.to_series().isin(species_gene_reference_hit),\n",
    "        corr_complement=lambda x: 1 - x.strain_corr,\n",
    "        dummy=False,\n",
    "    )\n",
    "    .sort_values('bitscore_ratio')\n",
    ")\n",
    "strain_scores\n",
    "\n",
    "fig, axs = plt.subplots(5, figsize=(6, 24), sharex=True, sharey=True)\n",
    "\n",
    "\n",
    "for ax, c in zip(axs.flatten(), ['not_bitscore_hit', 'bitscore_hit', 'dummy', 'species_gene_denovo', 'species_gene_reference']):\n",
    "    ax.scatter(\n",
    "        'corr_complement',\n",
    "        'strain_depth',\n",
    "        data=strain_scores[lambda x: ~x[c]],\n",
    "        s=5,\n",
    "        # c=c,\n",
    "        alpha=0.1   \n",
    "    )\n",
    "    ax.scatter(\n",
    "        'corr_complement',\n",
    "        'strain_depth',\n",
    "        data=strain_scores[lambda x: x[c]],\n",
    "        s=5,\n",
    "        # c=c,\n",
    "        alpha=0.5   \n",
    "    )\n",
    "    ax.axhline(depth_threshold, lw=1, linestyle='--')\n",
    "    ax.axhline(1, xmin=0., xmax=0.5, lw=1, linestyle='--', color='k')\n",
    "    ax.axvline(1 - corr_threshold, lw=1, linestyle='--')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('symlog', linthresh=1e-1)\n",
    "    ax.set_ylim(bottom=0)\n",
    "ax.invert_xaxis()\n",
    "ax.set_xlabel('correlation')\n",
    "ax.set_ylabel('depth ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_gene_depth = xr.load_dataarray(path['raw_gene_depth'])\n",
    "plt.hist(raw_gene_depth.sel(gene_id=species_gene_reference_hit, sample=fit_subset.sample).mean('gene_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_depth = pd.read_table(path['species_gene_mean_depth'], names=['sample', 'depth'], index_col='sample').squeeze()\n",
    "plt.hist(species_depth.loc[fit_subset.sample])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_depth.loc[fit_subset.sample].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(-4, 0, num=100)\n",
    "\n",
    "x = np.log10(1 - strain_scores[lambda x: x.species_gene_reference].strain_corr)\n",
    "kappa, loc, scale = sp.stats.laplace_asymmetric.fit(x)\n",
    "dist = sp.stats.laplace_asymmetric(kappa=kappa, loc=loc, scale=scale)\n",
    "\n",
    "\n",
    "plt.hist(x, bins=bins, density=True)\n",
    "plt.plot(bins, dist.pdf(bins))\n",
    "# plt.yscale('symlog', linthresh=1e-2, linscale=0.1)\n",
    "# plt.xscale('log')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qq = np.linspace(0, 1, num=len(x))\n",
    "x = np.log10(1 - strain_scores[lambda x: x.species_gene_reference].strain_corr.sort_values(ascending=False))\n",
    "plt.plot([0, 1], [0, 1], lw=1, c='k')\n",
    "plt.scatter(qq, dist.cdf(x), s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, figsize=(7, 10), sharex=True, sharey=True)\n",
    "\n",
    "for ax, c in zip(axs.flatten(), ['strain_corr_q', 'strain_depth_q']):\n",
    "    cax = make_axes_locatable(ax).append_axes('right', size='5%', pad=0.05)\n",
    "    artist = ax.scatter(\n",
    "        'corr_complement',\n",
    "        'strain_depth',\n",
    "        data=strain_scores,\n",
    "        s=5,\n",
    "        c=c,\n",
    "        alpha=0.1,\n",
    "        norm=mpl.colors.SymLogNorm(linthresh=1e-2, linscale=0.001),\n",
    "    )\n",
    "    cbar = fig.colorbar(artist, cax=cax)\n",
    "    cbar.solids.set_alpha(1.0)\n",
    "    ax.axhline(depth_threshold, lw=1, linestyle='--')\n",
    "    ax.axhline(1, xmin=0., xmax=0.5, lw=1, linestyle='--', color='k')\n",
    "    ax.axvline(1 - corr_threshold, lw=1, linestyle='--')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('symlog', linthresh=1e-1)\n",
    "ax.set_ylim(bottom=0)\n",
    "ax.invert_xaxis()\n",
    "ax.set_xlabel('correlation')\n",
    "ax.set_ylabel('depth ratio')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_asymetric_statistics(match_matrix):\n",
    "    tp_orf = idxwhere(match_matrix.any(axis=1))\n",
    "    fn_orf = idxwhere(~match_matrix.any(axis=1))\n",
    "    tp_gene = idxwhere(match_matrix.any(axis=0))\n",
    "    fp_gene = idxwhere(~match_matrix.any(axis=0))\n",
    "\n",
    "    n_tp_gene = len(tp_gene)\n",
    "    n_fp_gene = len(fp_gene)\n",
    "    n_fn_orf = len(fn_orf)\n",
    "    n_tp_orf = len(tp_orf)\n",
    "\n",
    "    precision = n_tp_gene / (n_tp_gene + n_fp_gene)\n",
    "    recall = n_tp_orf / (n_tp_orf + n_fn_orf)\n",
    "\n",
    "    return precision, recall\n",
    "\n",
    "midas_gene_list = idxwhere(strain_scores.strain_depth > 0)\n",
    "\n",
    "_correlation_q = strain_scores.strain_corr_q[midas_gene_list]\n",
    "_depth_q = strain_scores.strain_depth_q[midas_gene_list]\n",
    "_bitscore = orf_x_midas.unstack().reindex(columns=midas_gene_list, fill_value=0).astype(float)\n",
    "\n",
    "b_thresh = 0.5\n",
    "_bitscore_hit = _bitscore > b_thresh\n",
    "\n",
    "scaled_matching_gene = (\n",
    "    _bitscore_hit.T * (_bitscore_hit * _bitscore_hit.sum()).sum(1)\n",
    ").T\n",
    "_midas_1to1 = idxwhere(scaled_matching_gene.sum() <= 1)\n",
    "_orf_1to1 = idxwhere(scaled_matching_gene.sum(1) == 1)\n",
    "\n",
    "d_thresh = 0.01\n",
    "c_thresh = 0.01\n",
    "_spgc_hit = (_correlation_q >= c_thresh) & (_depth_q >= d_thresh)\n",
    "precision, recall = calculate_asymetric_statistics(\n",
    "    _bitscore_hit.loc[:, _spgc_hit]\n",
    ")\n",
    "precision_1to1, recall_1to1 = calculate_asymetric_statistics(\n",
    "    _bitscore_hit.loc[\n",
    "        _orf_1to1,\n",
    "        list(set(_midas_1to1) & set(idxwhere(_spgc_hit))),\n",
    "    ]\n",
    ")\n",
    "f1 = sp.stats.hmean([precision, recall])\n",
    "f1_1to1 = sp.stats.hmean([precision_1to1, recall_1to1])\n",
    "\n",
    "\n",
    "print(f\"precision={precision:.4f} ({precision_1to1:.4f})\")\n",
    "print(f\"recall={recall:.4f} ({recall_1to1:.4f})\")\n",
    "print(f\"f1={f1:.4f} ({f1_1to1:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_inferred_strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_table(path['reference_strain_accuracy'], index_col=0).sort_values('f1', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_asymetric_statistics(match_matrix):\n",
    "    tp_orf = idxwhere(match_matrix.any(axis=1))\n",
    "    fn_orf = idxwhere(~match_matrix.any(axis=1))\n",
    "    tp_gene = idxwhere(match_matrix.any(axis=0))\n",
    "    fp_gene = idxwhere(~match_matrix.any(axis=0))\n",
    "\n",
    "    n_tp_gene = len(tp_gene)\n",
    "    n_fp_gene = len(fp_gene)\n",
    "    n_fn_orf = len(fn_orf)\n",
    "    n_tp_orf = len(tp_orf)\n",
    "\n",
    "    precision = n_tp_gene / (n_tp_gene + n_fp_gene)\n",
    "    recall = n_tp_orf / (n_tp_orf + n_fn_orf)\n",
    "\n",
    "    return precision, recall\n",
    "\n",
    "midas_gene_list = idxwhere(strain_scores.strain_depth > 0)\n",
    "\n",
    "_correlation_q = strain_scores.strain_corr_q[midas_gene_list]\n",
    "_depth_q = strain_scores.strain_depth_q[midas_gene_list]\n",
    "_bitscore = orf_x_midas.unstack().reindex(columns=midas_gene_list, fill_value=0).astype(float)\n",
    "\n",
    "b_thresh = 0.5\n",
    "_bitscore_hit = _bitscore > b_thresh\n",
    "# Only consider\n",
    "#  - MIDAS genes that have <= 1 hit\n",
    "#  - ORFs that (1) don't hit any MIDAS genes with > 1 hit\n",
    "#  - and (2) hit exactly 1 MIDAS gene\n",
    "\n",
    "\n",
    "scaled_matching_gene = (\n",
    "    _bitscore_hit.T * (_bitscore_hit * _bitscore_hit.sum()).sum(1)\n",
    ").T\n",
    "_midas_1to1 = idxwhere(scaled_matching_gene.sum() <= 1)\n",
    "_orf_1to1 = idxwhere(scaled_matching_gene.sum(1) == 1)\n",
    "# _midas_multi_hit = _bitscore_hit.sum(0) > 1\n",
    "# _midas_1to1 = ~_midas_multi_hit\n",
    "# _orf_1to1 = (_bitscore_hit.loc[:, _midas_1to1].sum(1) == 1) & ~_bitscore_hit.loc[:, _midas_multi_hit].any(1)\n",
    "# _midas_1to1 = set(idxwhere(_midas_1to1))\n",
    "# _orf_1to1 = set(idxwhere(_orf_1to1))\n",
    "\n",
    "c_thresh_list = np.concatenate([[0], np.logspace(np.log10(0.005), np.log10(0.5), num=21)])\n",
    "d_thresh_list = np.concatenate([[0], np.logspace(np.log10(0.005), np.log10(0.5), num=21)])\n",
    "\n",
    "precision_result = np.empty((len(d_thresh_list), len(c_thresh_list)))\n",
    "recall_result = np.empty_like(precision_result)\n",
    "precision_result_1to1 = np.empty_like(precision_result)\n",
    "recall_result_1to1 = np.empty_like(precision_result)\n",
    "\n",
    "for (i, d_thresh), (j, c_thresh) in tqdm(\n",
    "    product(enumerate(d_thresh_list), enumerate(c_thresh_list)),\n",
    "    total=len(d_thresh_list) * len(c_thresh_list)\n",
    "):\n",
    "    _spgc_hit = (_correlation_q >= c_thresh) & (_depth_q >= d_thresh)\n",
    "    precision, recall = calculate_asymetric_statistics(\n",
    "        _bitscore_hit.loc[:, _spgc_hit]\n",
    "    )\n",
    "    precision_1to1, recall_1to1 = calculate_asymetric_statistics(\n",
    "        _bitscore_hit.loc[\n",
    "            _orf_1to1,\n",
    "            list(set(_midas_1to1) & set(idxwhere(_spgc_hit))),\n",
    "        ]\n",
    "    )#     tp_midas = set(idxwhere(_bitscore_hit.loc[:, _spgc_hit].any(axis=0)))  # MIDAS genes hit by both.\n",
    "#     fp_midas = set(idxwhere(~(_bitscore_hit.loc[:, _spgc_hit].any())))  # MIDAS genes were hit by SPGC but never by BLAST?\n",
    "#     fn_orf = set(idxwhere(~(_bitscore_hit.loc[:, _spgc_hit].any(axis=1))))  # How many ORFs were hit by BLAST but no matching SPGC hits?\n",
    "#     tp_orf = set(idxwhere((_spgc_hit & _bitscore_hit).any(axis=1)))  # How many ORFs were hit by BLAST and by SPGC?\n",
    "    \n",
    "#     n_tp_midas = len(tp_midas)\n",
    "#     n_fp_midas = len(fp_midas)\n",
    "#     n_fn_orf = len(fn_orf)\n",
    "#     n_tp_orf = len(tp_orf)\n",
    "    \n",
    "#     n_tp_1to1 = len(tp_midas & _midas_1to1)\n",
    "#     n_fp_1to1 = len(fp_midas & _midas_1to1)\n",
    "#     n_fn_1to1 = len(fn_orf & _orf_1to1)\n",
    "#     n_tn_1to1 = len(set(_spgc_hit) & _midas_1to1) - (n_tp_1to1 + n_fp_1to1 + n_fn_1to1)\n",
    "\n",
    "    precision_result[i, j] = precision\n",
    "    recall_result[i, j] = recall\n",
    "    precision_result_1to1[i, j] = precision_1to1\n",
    "    recall_result_1to1[i, j] = recall_1to1\n",
    "#     if (n_tp_midas + n_fp_midas) != 0:\n",
    "#         precision_result[i, j] = n_tp_midas / (n_tp_midas + n_fp_midas)\n",
    "#     else:\n",
    "#         precision_result[i, j] = 1\n",
    "\n",
    "#     if (n_tp_orf + n_fn_orf) != 0:\n",
    "#         recall_result[i, j] = n_tp_orf / (n_tp_orf + n_fn_orf)\n",
    "#     else:\n",
    "#         recall_result[i, j] = 0\n",
    "        \n",
    "#     if (n_tp_1to1 + n_fp_1to1) != 0:\n",
    "#         precision_result_1to1[i, j] = n_tp_1to1 / (n_tp_1to1 + n_fp_1to1)\n",
    "#     else:\n",
    "#         precision_result_1to1[i, j] = 1\n",
    "\n",
    "#     if (n_tp_1to1 + n_fn_1to1) != 0:\n",
    "#         recall_result_1to1[i, j] = n_tp_1to1 / (n_tp_1to1 + n_fn_1to1)\n",
    "#     else:\n",
    "#         recall_result_1to1[i, j] = 0\n",
    "    \n",
    "precision_result = pd.DataFrame(precision_result, index=d_thresh_list, columns=c_thresh_list).rename_axis(index='depth_threshold', columns='correlation_threshold')\n",
    "recall_result = pd.DataFrame(recall_result, index=d_thresh_list, columns=c_thresh_list).rename_axis(index='depth_threshold', columns='correlation_threshold')\n",
    "f1_result = pd.DataFrame(sp.stats.hmean(np.stack([precision_result, recall_result])), index=d_thresh_list, columns=c_thresh_list).rename_axis(index='depth_threshold', columns='correlation_threshold')\n",
    "\n",
    "precision_result_1to1 = pd.DataFrame(precision_result_1to1, index=d_thresh_list, columns=c_thresh_list).rename_axis(index='depth_threshold', columns='correlation_threshold')\n",
    "recall_result_1to1 = pd.DataFrame(recall_result_1to1, index=d_thresh_list, columns=c_thresh_list).rename_axis(index='depth_threshold', columns='correlation_threshold')\n",
    "f1_result_1to1 = pd.DataFrame(sp.stats.hmean(np.stack([precision_result_1to1, recall_result_1to1])), index=d_thresh_list, columns=c_thresh_list).rename_axis(index='depth_threshold', columns='correlation_threshold')\n",
    "\n",
    "\n",
    "    # print(f'{c_thresh}\\t{d_thresh}\\t{precision_midas:0.2f}\\t{recall_orf:0.2f}\\t{n_fp_midas}\\t{n_fn_orf}\\t{n_tp_midas}\\t{n_tp_orf}')\n",
    "\n",
    "# MIDAS genes that map to multiple ORFs, tend to have higher depth ratios.\n",
    "#sns.regplot(x=_bitscore_hit.loc[tp_orf, tp_midas].sum(axis=0), y=strain_scores.loc[tp_midas].strain_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, figsize=(5, 10))\n",
    "\n",
    "ax = axs[0]\n",
    "ax.set_title('precision')\n",
    "cax = make_axes_locatable(ax).append_axes('right', size='5%', pad=0.05)\n",
    "artist = ax.pcolormesh(c_thresh_list, d_thresh_list, precision_result, norm=mpl.colors.PowerNorm(1, vmin=0, vmax=1))\n",
    "ax.set_xscale('symlog', linthresh=1e-3, linscale=0.1)\n",
    "ax.set_yscale('symlog', linthresh=1e-3, linscale=0.1)\n",
    "# ax.set_yscale('symlog', linthresh=1e-1, linscale=0.5)\n",
    "ax.set_ylim(0)\n",
    "# ax.invert_xaxis()\n",
    "cbar = fig.colorbar(artist, cax=cax)\n",
    "# ax.axhline(strain_meta.depth_thresh_low.loc[top_inferred_strain], lw=1, linestyle='--', color='r')\n",
    "# ax.axvline(1 - strain_meta.corr_threshold.loc[top_inferred_strain], lw=1, linestyle='--', color='r')\n",
    "\n",
    "ax = axs[1]\n",
    "ax.set_title('recall')\n",
    "cax = make_axes_locatable(ax).append_axes('right', size='5%', pad=0.05)\n",
    "artist = ax.pcolormesh(c_thresh_list, d_thresh_list, recall_result, norm=mpl.colors.PowerNorm(1, vmin=0, vmax=1))\n",
    "ax.set_xscale('symlog', linthresh=1e-3, linscale=0.1)\n",
    "ax.set_yscale('symlog', linthresh=1e-3, linscale=0.1)\n",
    "# ax.set_yscale('symlog', linthresh=1e-1, linscale=0.5)\n",
    "ax.set_ylim(0)\n",
    "# ax.invert_xaxis()\n",
    "cbar = fig.colorbar(artist, cax=cax)\n",
    "# ax.axhline(strain_meta.depth_thresh_low.loc[top_inferred_strain], lw=1, linestyle='--', color='r')\n",
    "# ax.axvline(1 - strain_meta.corr_threshold.loc[top_inferred_strain], lw=1, linestyle='--', color='r')\n",
    "\n",
    "ax = axs[2]\n",
    "ax.set_title('f1')\n",
    "cax = make_axes_locatable(ax).append_axes('right', size='5%', pad=0.05)\n",
    "artist = ax.pcolormesh(c_thresh_list, d_thresh_list, f1_result, norm=mpl.colors.PowerNorm(1, vmin=0, vmax=1))\n",
    "ax.set_xscale('symlog', linthresh=1e-3, linscale=0.1)\n",
    "ax.set_yscale('symlog', linthresh=1e-3, linscale=0.1)\n",
    "# ax.set_yscale('symlog', linthresh=1e-1, linscale=0.5)\n",
    "ax.set_ylim(0)\n",
    "# ax.invert_xaxis()\n",
    "cbar = fig.colorbar(artist, cax=cax)\n",
    "# ax.axhline(strain_meta.depth_thresh_low.loc[top_inferred_strain], lw=1, linestyle='--', color='r')\n",
    "# ax.axvline(1 - strain_meta.corr_threshold.loc[top_inferred_strain], lw=1, linestyle='--', color='r')\n",
    "ax.set_xlabel('correlation quantile threshold')\n",
    "ax.set_ylabel('depth quantile threshold')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, figsize=(5, 10))\n",
    "\n",
    "ax = axs[0]\n",
    "ax.set_title('precision')\n",
    "cax = make_axes_locatable(ax).append_axes('right', size='5%', pad=0.05)\n",
    "artist = ax.pcolormesh(c_thresh_list, d_thresh_list, precision_result_1to1, norm=mpl.colors.PowerNorm(1, vmin=0, vmax=1))\n",
    "ax.set_xscale('symlog', linthresh=1e-3, linscale=0.1)\n",
    "ax.set_yscale('symlog', linthresh=1e-3, linscale=0.1)\n",
    "# ax.set_yscale('symlog', linthresh=1e-1, linscale=0.5)\n",
    "ax.set_ylim(0)\n",
    "# ax.invert_xaxis()\n",
    "cbar = fig.colorbar(artist, cax=cax)\n",
    "# ax.axhline(strain_meta.depth_thresh_low.loc[top_inferred_strain], lw=1, linestyle='--', color='r')\n",
    "# ax.axvline(1 - strain_meta.corr_threshold.loc[top_inferred_strain], lw=1, linestyle='--', color='r')\n",
    "\n",
    "ax = axs[1]\n",
    "ax.set_title('recall')\n",
    "cax = make_axes_locatable(ax).append_axes('right', size='5%', pad=0.05)\n",
    "artist = ax.pcolormesh(c_thresh_list, d_thresh_list, recall_result_1to1, norm=mpl.colors.PowerNorm(1, vmin=0, vmax=1))\n",
    "ax.set_xscale('symlog', linthresh=1e-3, linscale=0.1)\n",
    "ax.set_yscale('symlog', linthresh=1e-3, linscale=0.1)\n",
    "# ax.set_yscale('symlog', linthresh=1e-1, linscale=0.5)\n",
    "ax.set_ylim(0)\n",
    "# ax.invert_xaxis()\n",
    "cbar = fig.colorbar(artist, cax=cax)\n",
    "# ax.axhline(strain_meta.depth_thresh_low.loc[top_inferred_strain], lw=1, linestyle='--', color='r')\n",
    "# ax.axvline(1 - strain_meta.corr_threshold.loc[top_inferred_strain], lw=1, linestyle='--', color='r')\n",
    "\n",
    "ax = axs[2]\n",
    "ax.set_title('f1')\n",
    "cax = make_axes_locatable(ax).append_axes('right', size='5%', pad=0.05)\n",
    "artist = ax.pcolormesh(c_thresh_list, d_thresh_list, f1_result_1to1, norm=mpl.colors.PowerNorm(1, vmin=0, vmax=1))\n",
    "ax.set_xscale('symlog', linthresh=1e-3, linscale=0.1)\n",
    "ax.set_yscale('symlog', linthresh=1e-3, linscale=0.1)\n",
    "# ax.set_yscale('symlog', linthresh=1e-1, linscale=0.5)\n",
    "ax.set_ylim(0)\n",
    "# ax.invert_xaxis()\n",
    "cbar = fig.colorbar(artist, cax=cax)\n",
    "# ax.axhline(strain_meta.depth_thresh_low.loc[top_inferred_strain], lw=1, linestyle='--', color='r')\n",
    "# ax.axvline(1 - strain_meta.corr_threshold.loc[top_inferred_strain], lw=1, linestyle='--', color='r')\n",
    "ax.set_xlabel('correlation quantile threshold')\n",
    "ax.set_ylabel('depth quantile threshold')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, figsize=(5, 10))\n",
    "\n",
    "ax = axs[0]\n",
    "ax.set_title('precision')\n",
    "cax = make_axes_locatable(ax).append_axes('right', size='5%', pad=0.05)\n",
    "artist = ax.pcolormesh(c_thresh_list, d_thresh_list, precision_result_1to1 - precision_result, cmap='coolwarm', vmin=-0.1, vmax=0.1)\n",
    "ax.set_xscale('symlog', linthresh=1e-3, linscale=0.1)\n",
    "ax.set_yscale('symlog', linthresh=1e-3, linscale=0.1)\n",
    "# ax.set_yscale('symlog', linthresh=1e-1, linscale=0.5)\n",
    "ax.set_ylim(0)\n",
    "# ax.invert_xaxis()\n",
    "cbar = fig.colorbar(artist, cax=cax)\n",
    "# ax.axhline(strain_meta.depth_thresh_low.loc[top_inferred_strain], lw=1, linestyle='--', color='r')\n",
    "# ax.axvline(1 - strain_meta.corr_threshold.loc[top_inferred_strain], lw=1, linestyle='--', color='r')\n",
    "\n",
    "ax = axs[1]\n",
    "ax.set_title('recall')\n",
    "cax = make_axes_locatable(ax).append_axes('right', size='5%', pad=0.05)\n",
    "artist = ax.pcolormesh(c_thresh_list, d_thresh_list, recall_result_1to1 - recall_result, cmap='coolwarm', vmin=-0.1, vmax=0.1)\n",
    "ax.set_xscale('symlog', linthresh=1e-3, linscale=0.1)\n",
    "ax.set_yscale('symlog', linthresh=1e-3, linscale=0.1)\n",
    "# ax.set_yscale('symlog', linthresh=1e-1, linscale=0.5)\n",
    "ax.set_ylim(0)\n",
    "# ax.invert_xaxis()\n",
    "cbar = fig.colorbar(artist, cax=cax)\n",
    "# ax.axhline(strain_meta.depth_thresh_low.loc[top_inferred_strain], lw=1, linestyle='--', color='r')\n",
    "# ax.axvline(1 - strain_meta.corr_threshold.loc[top_inferred_strain], lw=1, linestyle='--', color='r')\n",
    "\n",
    "ax = axs[2]\n",
    "ax.set_title('f1')\n",
    "cax = make_axes_locatable(ax).append_axes('right', size='5%', pad=0.05)\n",
    "artist = ax.pcolormesh(c_thresh_list, d_thresh_list, f1_result_1to1 - f1_result, cmap='coolwarm', vmin=-0.1, vmax=0.1)\n",
    "ax.set_xscale('symlog', linthresh=1e-3, linscale=0.1)\n",
    "ax.set_yscale('symlog', linthresh=1e-3, linscale=0.1)\n",
    "# ax.set_yscale('symlog', linthresh=1e-1, linscale=0.5)\n",
    "ax.set_ylim(0)\n",
    "# ax.invert_xaxis()\n",
    "cbar = fig.colorbar(artist, cax=cax)\n",
    "# ax.axhline(strain_meta.depth_thresh_low.loc[top_inferred_strain], lw=1, linestyle='--', color='r')\n",
    "# ax.axvline(1 - strain_meta.corr_threshold.loc[top_inferred_strain], lw=1, linestyle='--', color='r')\n",
    "ax.set_xlabel('correlation quantile threshold')\n",
    "ax.set_ylabel('depth quantile threshold')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.contour(c_thresh_list, d_thresh_list, f1_result) #, levels=1 - np.logspace(np.log10(0.75), np.log10(0.01), num=11))\n",
    "\n",
    "cax = make_axes_locatable(ax).append_axes('right', size='5%', pad=0.05)\n",
    "artist = ax.scatter(\n",
    "    'strain_corr_q',\n",
    "    'strain_depth_q',\n",
    "    data=strain_scores,\n",
    "    s=5,\n",
    "    # c='bitscore_ratio',\n",
    "    norm=mpl.colors.LogNorm(),\n",
    "    alpha=0.1,\n",
    "    cmap='viridis_r',\n",
    ")\n",
    "cbar = fig.colorbar(artist, cax=cax)\n",
    "cbar.solids.set_alpha(1.0)\n",
    "\n",
    "\n",
    "ax.set_xscale('symlog', linthresh=1e-3, linscale=0.1)\n",
    "ax.set_yscale('symlog', linthresh=1e-3, linscale=0.1)\n",
    "ax.set_ylim(0)\n",
    "ax.invert_xaxis()\n",
    "# ax.axhline(strain_meta.depth_thresh_low.loc[top_inferred_strain], lw=1, linestyle='--', color='r')\n",
    "# ax.axvline(1 - strain_meta.corr_threshold.loc[top_inferred_strain], lw=1, linestyle='--', color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.contour(c_thresh_list, d_thresh_list, f1_result_1to1) #, levels=1 - np.logspace(np.log10(0.75), np.log10(0.01), num=11))\n",
    "\n",
    "cax = make_axes_locatable(ax).append_axes('right', size='5%', pad=0.05)\n",
    "artist = ax.scatter(\n",
    "    'strain_corr_q',\n",
    "    'strain_depth_q',\n",
    "    data=strain_scores,\n",
    "    s=5,\n",
    "    # c='bitscore_ratio',\n",
    "    norm=mpl.colors.LogNorm(),\n",
    "    alpha=0.1,\n",
    "    cmap='viridis_r',\n",
    ")\n",
    "cbar = fig.colorbar(artist, cax=cax)\n",
    "cbar.solids.set_alpha(1.0)\n",
    "\n",
    "\n",
    "ax.set_xscale('symlog', linthresh=1e-3, linscale=0.1)\n",
    "ax.set_yscale('symlog', linthresh=1e-3, linscale=0.1)\n",
    "ax.set_ylim(0)\n",
    "ax.invert_xaxis()\n",
    "# ax.axhline(strain_meta.depth_thresh_low.loc[top_inferred_strain], lw=1, linestyle='--', color='r')\n",
    "# ax.axvline(1 - strain_meta.corr_threshold.loc[top_inferred_strain], lw=1, linestyle='--', color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = strain_scores[lambda x: (x.bitscore_hit) & (x.strain_depth > 0)].join(gene_cluster.centroid_99_length).assign(\n",
    "        log_centroid_99_length=lambda x: np.log10(x.centroid_99_length / 3),\n",
    "        log_strain_depth=lambda x: np.log10(x.strain_depth),\n",
    "    )\n",
    "\n",
    "sns.regplot(\n",
    "    x='log_centroid_99_length',\n",
    "    y='log_strain_depth',\n",
    "    data=d,\n",
    "    lowess=True,\n",
    "    scatter_kws=dict(s=2),\n",
    ")\n",
    "plt.axhline(0, lw=1, linestyle='--', color='k')\n",
    "plt.ylim(-1.5, 1.5)\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = strain_scores[lambda x: (x.bitscore_hit) & (x.strain_depth > 0)].join(gene_cluster.centroid_99_length).assign(\n",
    "        log_centroid_99_length=lambda x: np.log10(x.centroid_99_length / 3),\n",
    "        log_strain_depth=lambda x: np.log10(x.strain_depth),\n",
    "    )\n",
    "\n",
    "sns.regplot(\n",
    "    x='log_centroid_99_length',\n",
    "    y='log_strain_depth',\n",
    "    data=d[d.species_gene_reference],\n",
    "    lowess=True,\n",
    "    scatter_kws=dict(s=2),\n",
    ")\n",
    "plt.axhline(0, lw=1, linestyle='--', color='k')\n",
    "plt.ylim(-1.5, 1.5)\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfacts",
   "language": "python",
   "name": "sfacts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}