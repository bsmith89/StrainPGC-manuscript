{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as _os\n",
    "_os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from operator import eq, sub\n",
    "import scipy.stats\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "from lib.pandas_util import idxwhere\n",
    "from lib.plot import construct_ordered_palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgen = pd.read_table('meta/mgen.tsv', index_col='library_id')\n",
    "preparation = pd.read_table('meta/preparation.tsv', index_col='preparation_id')\n",
    "stool = pd.read_table('meta/stool.tsv', index_col='stool_id')\n",
    "visit = pd.read_table('meta/visit.tsv', index_col='visit_id')\n",
    "subject = pd.read_table('meta/subject.tsv', index_col='subject_id')\n",
    "\n",
    "mgen_meta = (\n",
    "    mgen\n",
    "    .join(preparation.drop(columns='library_type'), on='preparation_id')\n",
    "    .join(stool, on='stool_id')\n",
    "    .join(visit, on='visit_id', rsuffix='_')\n",
    "    .join(subject, on='subject_id')\n",
    ")\n",
    "\n",
    "assert not any(mgen_meta.subject_id.isna())\n",
    "\n",
    "# meta.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_week = (\n",
    "    visit\n",
    "    .join(subject, on='subject_id')\n",
    "    .reset_index()\n",
    "    .dropna(subset=['subject_id', 'week_number'])\n",
    "    .groupby(['subject_id', 'week_number'])\n",
    "    .apply(lambda d: d.loc[d.notna().sum(1).sort_values().index[-1]])\n",
    "    .assign(subject_week_id=lambda x: x.subject_id + '_' + x.week_number.astype(int).astype(str))\n",
    "    .set_index('subject_week_id')\n",
    "    .join(stool.groupby('visit_id').fecal_calprotectin.mean(), on='visit_id')\n",
    ")\n",
    "\n",
    "mgen_to_subject_week = mgen_meta.dropna(subset=['week_number']).apply(lambda x: x.subject_id + '_' + str(int(x.week_number)), axis=1).rename('subject_week_id')\n",
    "mgen_to_subject_week\n",
    "\n",
    "#.groupby(['subject_id', 'week_number']).visit_id.count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_depth_with_minor = pd.read_table(\n",
    "    'data/hmp2.a.r.proc.gtpro.filt-poly05-cvrg05.fit-sfacts3-s75-g10000-seed0.collapse-10.strain_depth.tsv',\n",
    "    # names=['library_id', 'species_strain_id', 'depth'],\n",
    "    index_col=['sample', 'strain'],\n",
    ").squeeze().unstack('strain', fill_value=0).groupby(mgen_to_subject_week).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_depth = (\n",
    "    pd.read_table('data/hmp2.a.r.proc.gtpro.species_depth.tsv', index_col=['sample', 'species_id'])\n",
    "    .squeeze()\n",
    "    .unstack('species_id', fill_value=0)\n",
    "    .groupby(mgen_to_subject_week)\n",
    "    .sum()\n",
    ")\n",
    "species_depth.columns = species_depth.columns.astype(str)\n",
    "plt.hist(strain_depth_with_minor.sum(1) - species_depth.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.5\n",
    "\n",
    "strain_collapse = strain_depth_with_minor.columns.to_series()\n",
    "strain_other = strain_collapse.str.rsplit('-', 1).str[0] + '-other'\n",
    "strain_collapse = strain_collapse.where(strain_depth_with_minor.max() > thresh, strain_other)\n",
    "\n",
    "strain_collapse.value_counts().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_depth = strain_depth_with_minor.groupby(strain_collapse, axis='columns').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_taxonomy = pd.read_table('ref/gtpro/species_taxonomy_ext.tsv', names=['genome_id', 'species_id', 'taxonomy_string']).assign(species_id=lambda x: x.species_id.astype(str)).set_index('species_id')[['taxonomy_string']].assign(taxonomy_split=lambda x: x.taxonomy_string.str.split(';'))\n",
    "\n",
    "for level_name, level_number in [('p__', 1), ('c__', 2), ('o__', 3), ('f__', 4), ('g__', 5), ('s__', 6)]:\n",
    "    species_taxonomy = species_taxonomy.assign(**{level_name: species_taxonomy.taxonomy_split.apply(lambda x: x[level_number])}) \n",
    "species_taxonomy = species_taxonomy.drop(columns=['taxonomy_split'])\n",
    "    \n",
    "strain_taxonomy = strain_depth.columns.to_series().str.split('-').str[0].to_frame(name='species_id').join(species_taxonomy, on='species_id')\n",
    "\n",
    "species_taxonomy = strain_taxonomy.drop_duplicates(subset=['species_id']).set_index('species_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(strain_depth_with_minor.sum(1) - strain_depth.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_rabund = strain_depth.divide(strain_depth.sum(1), axis=0)\n",
    "plt.hist(np.log10(strain_rabund.max()), bins=np.linspace(-5, 0, num=51))\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_rabund = species_depth.divide(species_depth.sum(1), axis=0)\n",
    "plt.hist(np.log10(species_rabund.max()), bins=np.linspace(-5, 0, num=51))\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_depth = species_depth\n",
    "_n_taxa = len(_depth.columns)\n",
    "_rabund = _depth.divide(_depth.sum(1), axis=0)\n",
    "\n",
    "c = 'tab:blue'\n",
    "\n",
    "_prevalence = (_rabund > 1e-5).mean()\n",
    "_mean_rabund = _rabund.mean()\n",
    "_decreasing_prevalence = (_rabund > 1e-5).mean().sort_values(ascending=False).index\n",
    "_quantile_rabund = _rabund.loc[:, _decreasing_prevalence].cumsum(1).quantile([0.0, 0.05, 0.25, 0.5, 0.75, 0.95, 1.0]).T\n",
    "\n",
    "xx = np.arange(_n_taxa)\n",
    "plt.plot(xx, _quantile_rabund[0.5], c=c, lw=2, label='median_rabund')\n",
    "plt.fill_between(xx, _quantile_rabund[0.0], _quantile_rabund[1.0], color=c, alpha=0.05, edgecolor=None)\n",
    "plt.fill_between(xx, _quantile_rabund[0.05], _quantile_rabund[0.95], color=c, alpha=0.2, edgecolor=None)\n",
    "plt.fill_between(xx, _quantile_rabund[0.25], _quantile_rabund[0.75], color=c, alpha=0.2, edgecolor=None)\n",
    "\n",
    "plt.axvline((_quantile_rabund[0.0] < 0.99).sum(), linestyle='--', lw=1, color='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_depth = strain_depth\n",
    "_n_taxa = len(_depth.columns)\n",
    "_rabund = _depth.divide(_depth.sum(1), axis=0)\n",
    "\n",
    "c = 'tab:blue'\n",
    "\n",
    "_prevalence = (_rabund > 1e-5).mean()\n",
    "_mean_rabund = _rabund.mean()\n",
    "_decreasing_prevalence = (_rabund > 1e-5).mean().sort_values(ascending=False).index\n",
    "_quantile_rabund = _rabund.loc[:, _decreasing_prevalence].cumsum(1).quantile([0.0, 0.05, 0.25, 0.5, 0.75, 0.95, 1.0]).T\n",
    "\n",
    "xx = np.arange(_n_taxa)\n",
    "plt.plot(xx, _quantile_rabund[0.5], c=c, lw=2, label='median_rabund')\n",
    "plt.fill_between(xx, _quantile_rabund[0.0], _quantile_rabund[1.0], color=c, alpha=0.05, edgecolor=None)\n",
    "plt.fill_between(xx, _quantile_rabund[0.05], _quantile_rabund[0.95], color=c, alpha=0.2, edgecolor=None)\n",
    "plt.fill_between(xx, _quantile_rabund[0.25], _quantile_rabund[0.75], color=c, alpha=0.2, edgecolor=None)\n",
    "\n",
    "plt.axvline((_quantile_rabund[0.0] < 0.99).sum(), linestyle='--', lw=1, color='grey')\n",
    "\n",
    "print('Unique species:', len(set(map(lambda s: s.split('-')[0], idxwhere(_quantile_rabund[0.0] < 0.99)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 20))\n",
    "abx_status_matrix = subject_week.groupby(['subject_id', 'week_number']).status_antibiotics.any().astype(float)\n",
    "cm = sns.heatmap(abx_status_matrix.unstack(), cmap='coolwarm', yticklabels=1, ax=ax, cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = abx_status_matrix.unstack().apply(lambda x: x.dropna().mean(), axis=1).to_frame(name='frac_libraries_during_abx').join(subject)\n",
    "sns.stripplot(y='frac_libraries_during_abx', x='ibd_diagnosis', hue='sex', data=d, alpha=0.3, dodge=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 20))\n",
    "\n",
    "v = subject_week.assign(has_mgen=lambda d: d.index.to_series().isin(species_depth.index))\n",
    "has_mgen_matrix = v.groupby(['subject_id', 'week_number']).has_mgen.any().astype(float)\n",
    "\n",
    "sns.heatmap(has_mgen_matrix.unstack(), cmap='coolwarm', yticklabels=1, ax=ax, cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 20))\n",
    "\n",
    "sns.heatmap(subject_week.set_index(['subject_id', 'week_number']).fecal_calprotectin.unstack(), yticklabels=1, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgen_id_list_matrix = mgen_meta.reset_index().groupby(['subject_id', 'week_number']).library_id.apply(list)\n",
    "mgen_id_list_matrix.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = (\n",
    "    pd.DataFrame(dict(\n",
    "        has_mgen=has_mgen_matrix,\n",
    "        library_id_list=mgen_id_list_matrix,\n",
    "        status_antibiotics=abx_status_matrix.astype(bool)\n",
    "    ))\n",
    "    .reset_index()\n",
    "    .assign(subject_week_id=lambda x: x.subject_id + '_' + x.week_number.astype(int).astype(str))\n",
    "    .set_index('subject_week_id')\n",
    "    )\n",
    "\n",
    "\n",
    "# For each subject, find a pair of visits with metagenomes where the first has no antibiotics (and not in the most-recent week, either),\n",
    "# and the second sample does have antibiotics\n",
    "# and they're in consecutive fortnights\n",
    "\n",
    "def _find_antibiotic_comparison_pairs(data):\n",
    "    d0 = data.sort_values(['subject_id', 'week_number']).copy()\n",
    "    d0['has_mgen'] = d0['has_mgen'].astype(bool)\n",
    "    d1 = (\n",
    "        d0.assign(\n",
    "            maybe_control=lambda x: ~(x.status_antibiotics | x.status_antibiotics.shift(1)),  # No abx this visit or last\n",
    "            maybe_abx=lambda x: (x.status_antibiotics & (~x.status_antibiotics).shift(1)),  # Abx this visit but not last\n",
    "        )\n",
    "        [lambda x: x.has_mgen]\n",
    "        .assign(\n",
    "            last_mgen_maybe_control=lambda x: x.maybe_control.shift(1),\n",
    "            next_mgen_maybe_abx=lambda x: x.maybe_abx.shift(-1),\n",
    "            time_delta_last_mgen=lambda x: x.week_number - x.week_number.shift(1),\n",
    "            time_delta_next_mgen=lambda x: x.week_number.shift(-1) - x.week_number,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    out = d1[lambda x: (\n",
    "        (x.maybe_control & x.next_mgen_maybe_abx & (x.time_delta_next_mgen <= 2.0)) # First of a pair\n",
    "        | (x.maybe_abx & x.last_mgen_maybe_control & (x.time_delta_last_mgen <= 2.0)) # Second of a pair\n",
    "    )].head(2).index.values\n",
    "    if len(out) == 2:\n",
    "        return pd.Series(out, index=['pre', 'post'])\n",
    "    else:\n",
    "        return pd.Series(np.nan, index=['pre', 'post'])\n",
    "\n",
    "abx_perturbation_pairs = (\n",
    "    d.groupby('subject_id')\n",
    "    .apply(_find_antibiotic_comparison_pairs)\n",
    "    .dropna()\n",
    ")\n",
    "abx_perturbation_pairs\n",
    "\n",
    "# For each subject, find a pair of visits with metagenomes where neither has antibiotics, (and not in the most-recent week, either),\n",
    "# and they're in consecutive fortnights\n",
    "\n",
    "def _find_dummy_comparison_pairs(data):\n",
    "    d0 = data.sort_values(['subject_id', 'week_number']).copy()\n",
    "    d0['has_mgen'] = d0['has_mgen'].astype(bool)\n",
    "    d1 = (\n",
    "        d0.assign(\n",
    "            maybe_control=lambda x: ~(x.status_antibiotics | x.status_antibiotics.shift(1)),  # No abx this visit or last\n",
    "            maybe_dummy=lambda x: ~(x.status_antibiotics | x.status_antibiotics.shift(1)),  # No abx this visit or last\n",
    "        )\n",
    "        [lambda x: x.has_mgen]\n",
    "        .assign(\n",
    "            last_mgen_maybe_control=lambda x: x.maybe_control.shift(1),\n",
    "            next_mgen_maybe_dummy=lambda x: x.maybe_dummy.shift(-1),\n",
    "            time_delta_last_mgen=lambda x: x.week_number - x.week_number.shift(1),\n",
    "            time_delta_next_mgen=lambda x: x.week_number.shift(-1) - x.week_number,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    out = d1[lambda x: (\n",
    "        (x.maybe_control & x.next_mgen_maybe_dummy & (x.time_delta_next_mgen <= 2.0)) # First of a pair\n",
    "        | (x.maybe_dummy & x.last_mgen_maybe_control & (x.time_delta_last_mgen <= 2.0)) # Second of a pair\n",
    "    )].head(2).index.values\n",
    "    if len(out) == 2:\n",
    "        return pd.Series(out, index=['pre', 'post'])\n",
    "    else:\n",
    "        return pd.Series(np.nan, index=['pre', 'post'])\n",
    "\n",
    "dummy_perturbation_pairs = (\n",
    "    d.groupby('subject_id')\n",
    "    .apply(_find_dummy_comparison_pairs)\n",
    "    .dropna()\n",
    ")\n",
    "dummy_perturbation_pairs\n",
    "\n",
    "subjects_with_both_abx_and_dummy = list(set(abx_perturbation_pairs.index) & set(dummy_perturbation_pairs.index))\n",
    "\n",
    "abx_perturbation_pairs = abx_perturbation_pairs.loc[subjects_with_both_abx_and_dummy]\n",
    "dummy_perturbation_pairs = dummy_perturbation_pairs.loc[subjects_with_both_abx_and_dummy]\n",
    "\n",
    "perturbation_pairs = abx_perturbation_pairs.join(dummy_perturbation_pairs, lsuffix='_abx', rsuffix='_dummy')\n",
    "perturbation_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diversity_func = lambda k: (strain_rabund.loc[perturbation_pairs[k]] > 1e-5).sum(1).values\n",
    "d = (\n",
    "    pd.DataFrame({k: diversity_func(k) for k in perturbation_pairs.columns}, index=perturbation_pairs.index)\n",
    "    .rename_axis(columns='sample_type')\n",
    "\n",
    ")\n",
    "\n",
    "sns.swarmplot(x='sample_type', y='diversity', data=d.stack().rename('diversity').reset_index())\n",
    "plt.yscale('symlog')\n",
    "plt.ylim(bottom=-1)\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['post_abx']))\n",
    "print(sp.stats.wilcoxon(d['pre_dummy'], d['post_dummy']))\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['pre_dummy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tax_subset = idxwhere(strain_taxonomy.taxonomy_string.str.startswith('d__Bacteria;p__Bacteroidota;'))\n",
    "diversity_func = lambda k: (strain_rabund.loc[perturbation_pairs[k], _tax_subset] > 1e-5).sum(1).values\n",
    "d = (\n",
    "    pd.DataFrame({k: diversity_func(k) for k in perturbation_pairs.columns}, index=perturbation_pairs.index)\n",
    "    .rename_axis(columns='sample_type')\n",
    "\n",
    ")\n",
    "\n",
    "sns.swarmplot(x='sample_type', y='diversity', data=d.stack().rename('diversity').reset_index())\n",
    "plt.yscale('symlog')\n",
    "plt.ylim(bottom=-1)\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['post_abx']))\n",
    "print(sp.stats.wilcoxon(d['pre_dummy'], d['post_dummy']))\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['pre_dummy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tax_subset = idxwhere(strain_taxonomy.taxonomy_string.str.startswith('d__Bacteria;p__Proteobacteria;'))  # idxwhere(strain_taxonomy.p__ == 'd__Bacteria;p__Proteobacteria')\n",
    "diversity_func = lambda k: (strain_rabund.loc[perturbation_pairs[k], _tax_subset] > 1e-5).sum(1).values\n",
    "d = (\n",
    "    pd.DataFrame({k: diversity_func(k) for k in perturbation_pairs.columns}, index=perturbation_pairs.index)\n",
    "    .rename_axis(columns='sample_type')\n",
    "\n",
    ")\n",
    "\n",
    "sns.swarmplot(x='sample_type', y='diversity', data=d.stack().rename('diversity').reset_index())\n",
    "plt.yscale('symlog')\n",
    "plt.ylim(bottom=-1)\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['post_abx']))\n",
    "print(sp.stats.wilcoxon(d['pre_dummy'], d['post_dummy']))\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['pre_dummy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tax_subset = idxwhere(strain_taxonomy.taxonomy_string.str.startswith('d__Bacteria;p__Firmicutes;'))\n",
    "diversity_func = lambda k: (strain_rabund.loc[perturbation_pairs[k], _tax_subset] > 1e-5).sum(1).values\n",
    "d = (\n",
    "    pd.DataFrame({k: diversity_func(k) for k in perturbation_pairs.columns}, index=perturbation_pairs.index)\n",
    "    .rename_axis(columns='sample_type')\n",
    "\n",
    ")\n",
    "\n",
    "sns.swarmplot(x='sample_type', y='diversity', data=d.stack().rename('diversity').reset_index())\n",
    "plt.yscale('symlog')\n",
    "plt.ylim(bottom=-1)\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['post_abx']))\n",
    "print(sp.stats.wilcoxon(d['pre_dummy'], d['post_dummy']))\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['pre_dummy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tax_subset = idxwhere(strain_taxonomy.taxonomy_string.str.startswith('d__Bacteria;p__Firmicutes_A;'))\n",
    "diversity_func = lambda k: (strain_rabund.loc[perturbation_pairs[k], _tax_subset] > 1e-5).sum(1).values\n",
    "d = (\n",
    "    pd.DataFrame({k: diversity_func(k) for k in perturbation_pairs.columns}, index=perturbation_pairs.index)\n",
    "    .rename_axis(columns='sample_type')\n",
    "\n",
    ")\n",
    "\n",
    "sns.swarmplot(x='sample_type', y='diversity', data=d.stack().rename('diversity').reset_index())\n",
    "plt.yscale('symlog')\n",
    "plt.ylim(bottom=-1)\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['post_abx']))\n",
    "print(sp.stats.wilcoxon(d['pre_dummy'], d['post_dummy']))\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['pre_dummy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tax_subset = idxwhere(strain_taxonomy.taxonomy_string.str.startswith('d__Bacteria;p__Firmicutes_C;'))\n",
    "diversity_func = lambda k: (strain_rabund.loc[perturbation_pairs[k], _tax_subset] > 1e-5).sum(1).values\n",
    "d = (\n",
    "    pd.DataFrame({k: diversity_func(k) for k in perturbation_pairs.columns}, index=perturbation_pairs.index)\n",
    "    .rename_axis(columns='sample_type')\n",
    "\n",
    ")\n",
    "\n",
    "sns.swarmplot(x='sample_type', y='diversity', data=d.stack().rename('diversity').reset_index())\n",
    "plt.yscale('symlog')\n",
    "plt.ylim(bottom=-1)\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['post_abx']))\n",
    "print(sp.stats.wilcoxon(d['pre_dummy'], d['post_dummy']))\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['pre_dummy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tax_subset = idxwhere(strain_taxonomy.taxonomy_string.str.startswith('d__Bacteria;p__Actinobacteriota;'))\n",
    "diversity_func = lambda k: (strain_rabund.loc[perturbation_pairs[k], _tax_subset] > 1e-5).sum(1).values\n",
    "d = (\n",
    "    pd.DataFrame({k: diversity_func(k) for k in perturbation_pairs.columns}, index=perturbation_pairs.index)\n",
    "    .rename_axis(columns='sample_type')\n",
    "\n",
    ")\n",
    "\n",
    "sns.swarmplot(x='sample_type', y='diversity', data=d.stack().rename('diversity').reset_index())\n",
    "plt.yscale('symlog')\n",
    "plt.ylim(bottom=-1)\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['post_abx']))\n",
    "print(sp.stats.wilcoxon(d['pre_dummy'], d['post_dummy']))\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['pre_dummy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tax_subset = idxwhere(species_taxonomy.taxonomy_string.str.startswith('d__Bacteria;p__Firmicutes_A;'))\n",
    "_func = lambda ii: (species_rabund.loc[ii, _tax_subset]).sum(1).values\n",
    "d = (\n",
    "    pd.DataFrame({k: _func(perturbation_pairs[k]) for k in perturbation_pairs.columns}, index=perturbation_pairs.index)\n",
    "    .rename_axis(columns='sample_type')\n",
    "\n",
    ")\n",
    "\n",
    "sns.swarmplot(x='sample_type', y='value', data=d.stack().rename('value').reset_index())\n",
    "# plt.yscale('symlog')\n",
    "# plt.ylim(bottom=-1)\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['post_abx']))\n",
    "print(sp.stats.wilcoxon(d['pre_dummy'], d['post_dummy']))\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['pre_dummy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tax_subset = idxwhere(species_taxonomy.taxonomy_string.str.startswith('d__Bacteria;p__Firmicutes_C;'))\n",
    "_func = lambda ii: (species_rabund.loc[ii, _tax_subset]).sum(1).values\n",
    "d = (\n",
    "    pd.DataFrame({k: _func(perturbation_pairs[k]) for k in perturbation_pairs.columns}, index=perturbation_pairs.index)\n",
    "    .rename_axis(columns='sample_type')\n",
    "\n",
    ")\n",
    "\n",
    "sns.swarmplot(x='sample_type', y='value', data=d.stack().rename('value').reset_index())\n",
    "# plt.yscale('symlog')\n",
    "# plt.ylim(bottom=-1)\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['post_abx']))\n",
    "print(sp.stats.wilcoxon(d['pre_dummy'], d['post_dummy']))\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['pre_dummy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tax_subset = idxwhere(species_taxonomy.taxonomy_string.str.startswith('d__Bacteria;p__Proteobacteria;'))\n",
    "_func = lambda ii: (species_rabund.loc[ii, _tax_subset]).sum(1).values\n",
    "d = (\n",
    "    pd.DataFrame({k: _func(perturbation_pairs[k]) for k in perturbation_pairs.columns}, index=perturbation_pairs.index)\n",
    "    .rename_axis(columns='sample_type')\n",
    "\n",
    ")\n",
    "\n",
    "sns.stripplot(x='sample_type', y='value', hue='ibd_diagnosis', data=d.stack().to_frame(name='value').join(subject).reset_index())\n",
    "# plt.yscale('symlog')\n",
    "# plt.ylim(bottom=-1)\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['post_abx']))\n",
    "print(sp.stats.wilcoxon(d['pre_dummy'], d['post_dummy']))\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['pre_dummy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_bc_dist = pd.DataFrame(sp.spatial.distance.squareform(sp.spatial.distance.pdist(species_rabund, metric='braycurtis')), index=species_rabund.index, columns=species_rabund.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abx_perturbation = [species_bc_dist.loc[pair.pre_abx, pair.post_abx] for _, pair in perturbation_pairs.iterrows()]\n",
    "dummy_perturbation = [species_bc_dist.loc[pair.pre_dummy, pair.post_dummy] for _, pair in perturbation_pairs.iterrows()]\n",
    "\n",
    "d = pd.DataFrame(dict(abx=abx_perturbation, dummy=dummy_perturbation), index=perturbation_pairs.index).rename_axis(columns='pair_type')\n",
    "sns.stripplot('pair_type', 'bc', data=d.unstack().to_frame('bc').reset_index())\n",
    "\n",
    "print(sp.stats.wilcoxon(d['abx'], d['dummy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_bc_dist = pd.DataFrame(sp.spatial.distance.squareform(sp.spatial.distance.pdist(strain_rabund, metric='braycurtis')), index=strain_rabund.index, columns=strain_rabund.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abx_perturbation = [strain_bc_dist.loc[pair.pre_abx, pair.post_abx] for _, pair in perturbation_pairs.iterrows()]\n",
    "dummy_perturbation = [strain_bc_dist.loc[pair.pre_dummy, pair.post_dummy] for _, pair in perturbation_pairs.iterrows()]\n",
    "\n",
    "d = pd.DataFrame(dict(abx=abx_perturbation, dummy=dummy_perturbation), index=perturbation_pairs.index).rename_axis(columns='pair_type')\n",
    "sns.stripplot('pair_type', 'bc', data=d.unstack().to_frame('bc').reset_index())\n",
    "\n",
    "print(sp.stats.wilcoxon(d['abx'], d['dummy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_jc_dist = pd.DataFrame(sp.spatial.distance.squareform(sp.spatial.distance.pdist(\n",
    "    strain_rabund > 1e-5,\n",
    "    metric='jaccard',\n",
    ")), index=strain_rabund.index, columns=strain_rabund.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abx_perturbation = [strain_jc_dist.loc[pair.pre_abx, pair.post_abx] for _, pair in perturbation_pairs.iterrows()]\n",
    "dummy_perturbation = [strain_jc_dist.loc[pair.pre_dummy, pair.post_dummy] for _, pair in perturbation_pairs.iterrows()]\n",
    "\n",
    "d = pd.DataFrame(dict(abx=abx_perturbation, dummy=dummy_perturbation), index=perturbation_pairs.index).rename_axis(columns='pair_type')\n",
    "sns.stripplot('pair_type', 'jc', data=d.unstack().to_frame('jc').reset_index())\n",
    "\n",
    "print(sp.stats.wilcoxon(d['abx'], d['dummy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_rabund = strain_rabund.loc[:, idxwhere(strain_taxonomy.taxonomy_string.str.startswith('d__Bacteria;p__Bacteroidota;'))].apply(lambda x: x / x.sum(), axis=1)\n",
    "_bc_dist = pd.DataFrame(sp.spatial.distance.squareform(sp.spatial.distance.pdist(_rabund, metric='braycurtis')), index=_rabund.index, columns=_rabund.index)\n",
    "\n",
    "abx_perturbation = [_bc_dist.loc[pair.pre_abx, pair.post_abx] for _, pair in perturbation_pairs.iterrows()]\n",
    "dummy_perturbation = [_bc_dist.loc[pair.pre_dummy, pair.post_dummy] for _, pair in perturbation_pairs.iterrows()]\n",
    "\n",
    "d = pd.DataFrame(dict(abx=abx_perturbation, dummy=dummy_perturbation), index=perturbation_pairs.index).rename_axis(columns='pair_type').dropna()\n",
    "sns.stripplot('pair_type', 'bc', data=d.unstack().to_frame('bc').reset_index())\n",
    "\n",
    "print(sp.stats.wilcoxon(d['abx'], d['dummy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_rabund = strain_rabund.loc[:, idxwhere(strain_taxonomy.taxonomy_string.str.startswith('d__Bacteria;p__Proteobacteria;'))].apply(lambda x: x / x.sum(), axis=1)\n",
    "_bc_dist = pd.DataFrame(sp.spatial.distance.squareform(sp.spatial.distance.pdist(_rabund, metric='braycurtis')), index=_rabund.index, columns=_rabund.index)\n",
    "\n",
    "abx_perturbation = [_bc_dist.loc[pair.pre_abx, pair.post_abx] for _, pair in perturbation_pairs.iterrows()]\n",
    "dummy_perturbation = [_bc_dist.loc[pair.pre_dummy, pair.post_dummy] for _, pair in perturbation_pairs.iterrows()]\n",
    "\n",
    "d = pd.DataFrame(dict(abx=abx_perturbation, dummy=dummy_perturbation), index=perturbation_pairs.index).rename_axis(columns='pair_type').dropna()\n",
    "sns.stripplot('pair_type', 'bc', data=d.unstack().to_frame('bc').reset_index())\n",
    "\n",
    "print(sp.stats.wilcoxon(d['abx'], d['dummy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_rabund = strain_rabund.loc[:, idxwhere(strain_taxonomy.taxonomy_string.str.startswith('d__Bacteria;p__Firmicutes;'))].apply(lambda x: x / x.sum(), axis=1)\n",
    "_bc_dist = pd.DataFrame(sp.spatial.distance.squareform(sp.spatial.distance.pdist(_rabund, metric='braycurtis')), index=_rabund.index, columns=_rabund.index)\n",
    "\n",
    "abx_perturbation = [_bc_dist.loc[pair.pre_abx, pair.post_abx] for _, pair in perturbation_pairs.iterrows()]\n",
    "dummy_perturbation = [_bc_dist.loc[pair.pre_dummy, pair.post_dummy] for _, pair in perturbation_pairs.iterrows()]\n",
    "\n",
    "d = pd.DataFrame(dict(abx=abx_perturbation, dummy=dummy_perturbation), index=perturbation_pairs.index).rename_axis(columns='pair_type').dropna()\n",
    "sns.stripplot('pair_type', 'bc', data=d.unstack().to_frame('bc').reset_index())\n",
    "\n",
    "print(sp.stats.wilcoxon(d['abx'], d['dummy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_rabund = strain_rabund.loc[:, idxwhere(strain_taxonomy.taxonomy_string.str.startswith('d__Bacteria;p__Firmicutes_A;'))].apply(lambda x: x / x.sum(), axis=1)\n",
    "_bc_dist = pd.DataFrame(sp.spatial.distance.squareform(sp.spatial.distance.pdist(_rabund, metric='braycurtis')), index=_rabund.index, columns=_rabund.index)\n",
    "\n",
    "abx_perturbation = [_bc_dist.loc[pair.pre_abx, pair.post_abx] for _, pair in perturbation_pairs.iterrows()]\n",
    "dummy_perturbation = [_bc_dist.loc[pair.pre_dummy, pair.post_dummy] for _, pair in perturbation_pairs.iterrows()]\n",
    "\n",
    "d = pd.DataFrame(dict(abx=abx_perturbation, dummy=dummy_perturbation), index=perturbation_pairs.index).rename_axis(columns='pair_type').dropna()\n",
    "sns.stripplot('pair_type', 'bc', data=d.unstack().to_frame('bc').reset_index())\n",
    "\n",
    "print(sp.stats.wilcoxon(d['abx'], d['dummy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_rabund = strain_rabund.loc[:, idxwhere(strain_taxonomy.taxonomy_string.str.startswith('d__Bacteria;p__Firmicutes_C;'))].apply(lambda x: x / x.sum(), axis=1)\n",
    "_bc_dist = pd.DataFrame(sp.spatial.distance.squareform(sp.spatial.distance.pdist(_rabund, metric='braycurtis')), index=_rabund.index, columns=_rabund.index)\n",
    "\n",
    "abx_perturbation = [_bc_dist.loc[pair.pre_abx, pair.post_abx] for _, pair in perturbation_pairs.iterrows()]\n",
    "dummy_perturbation = [_bc_dist.loc[pair.pre_dummy, pair.post_dummy] for _, pair in perturbation_pairs.iterrows()]\n",
    "\n",
    "d = pd.DataFrame(dict(abx=abx_perturbation, dummy=dummy_perturbation), index=perturbation_pairs.index).rename_axis(columns='pair_type').dropna()\n",
    "sns.stripplot('pair_type', 'bc', data=d.unstack().to_frame('bc').reset_index())\n",
    "\n",
    "print(sp.stats.wilcoxon(d['abx'], d['dummy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_rabund = strain_rabund.loc[:, idxwhere(strain_taxonomy.taxonomy_string.str.startswith('d__Bacteria;p__Actinobacteriota;'))].apply(lambda x: x / x.sum(), axis=1)\n",
    "_bc_dist = pd.DataFrame(sp.spatial.distance.squareform(sp.spatial.distance.pdist(_rabund, metric='braycurtis')), index=_rabund.index, columns=_rabund.index)\n",
    "\n",
    "abx_perturbation = [_bc_dist.loc[pair.pre_abx, pair.post_abx] for _, pair in perturbation_pairs.iterrows()]\n",
    "dummy_perturbation = [_bc_dist.loc[pair.pre_dummy, pair.post_dummy] for _, pair in perturbation_pairs.iterrows()]\n",
    "\n",
    "d = pd.DataFrame(dict(abx=abx_perturbation, dummy=dummy_perturbation), index=perturbation_pairs.index).rename_axis(columns='pair_type').dropna()\n",
    "sns.stripplot('pair_type', 'bc', data=d.unstack().to_frame('bc').reset_index())\n",
    "\n",
    "print(sp.stats.wilcoxon(d['abx'], d['dummy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tax_subset = idxwhere(species_taxonomy.taxonomy_string.str.startswith('d__Bacteria;p__Firmicutes_A;c__Clostridia;'))\n",
    "_func = lambda ii: (species_rabund.loc[ii, _tax_subset]).sum(1).values\n",
    "d = (\n",
    "    pd.DataFrame({k: _func(perturbation_pairs[k]) for k in perturbation_pairs.columns}, index=perturbation_pairs.index)\n",
    "    .rename_axis(columns='sample_type')\n",
    "\n",
    ")\n",
    "\n",
    "sns.swarmplot(x='sample_type', y='value', data=d.stack().rename('value').reset_index())\n",
    "# plt.yscale('symlog')\n",
    "# plt.ylim(bottom=-1)\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['post_abx']))\n",
    "print(sp.stats.wilcoxon(d['pre_dummy'], d['post_dummy']))\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['pre_dummy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    species_rabund\n",
    "    .groupby(species_taxonomy[\n",
    "        lambda x: x.taxonomy_string.str.startswith('d__Bacteria;p__Firmicutes_A;c__Clostridia;o__Lachnospirales;f__Lachnospiraceae')\n",
    "    ].taxonomy_string, axis='columns')\n",
    "    .sum()\n",
    "    .groupby(subject_week.subject_id)\n",
    "    .mean()\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(20)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tax_subset = idxwhere(species_taxonomy.taxonomy_string.str.startswith('d__Bacteria;p__Firmicutes_A;c__Clostridia;o__Lachnospirales;f__Lachnospiraceae;'))\n",
    "_func = lambda ii: (species_rabund.loc[ii, _tax_subset]).sum(1).values\n",
    "d = (\n",
    "    pd.DataFrame({k: _func(perturbation_pairs[k]) for k in perturbation_pairs.columns}, index=perturbation_pairs.index)\n",
    "    .rename_axis(columns='sample_type')\n",
    "\n",
    ")\n",
    "palette = construct_ordered_palette(perturbation_pairs.index, cm='tab20')\n",
    "shift = {'abx': 0, 'dummy': 1.25}\n",
    "\n",
    "for label, left, right in [('abx', 'pre_abx', 'post_abx'), ('dummy', 'pre_dummy', 'post_dummy')]:\n",
    "    for subject_id in d.index:\n",
    "        xy = [d.loc[subject_id, left]], [d.loc[subject_id, right]]\n",
    "        plt.plot(np.array([0, 1]) + shift[label], [d.loc[subject_id, left], d.loc[subject_id, right]], alpha=0.75, color=palette[subject_id])\n",
    "plt.yscale('symlog', linthresh=1e-5)\n",
    "plt.ylim(bottom=-1e-6)\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['post_abx']))\n",
    "print(sp.stats.wilcoxon(d['pre_dummy'], d['post_dummy']))\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['pre_dummy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tax_subset = idxwhere(species_taxonomy.taxonomy_string.str.startswith('d__Bacteria;p__Firmicutes_A;c__Clostridia;o__Lachnospirales;f__Lachnospiraceae;g__Roseburia;s__Roseburia intestinalis'))\n",
    "_func = lambda ii: (species_rabund.loc[ii, _tax_subset]).sum(1).values\n",
    "d = (\n",
    "    pd.DataFrame({k: _func(perturbation_pairs[k]) for k in perturbation_pairs.columns}, index=perturbation_pairs.index)\n",
    "    .rename_axis(columns='sample_type')\n",
    "\n",
    ")\n",
    "palette = construct_ordered_palette(perturbation_pairs.index, cm='tab20')\n",
    "shift = {'abx': 0, 'dummy': 1.25}\n",
    "\n",
    "for label, left, right in [('abx', 'pre_abx', 'post_abx'), ('dummy', 'pre_dummy', 'post_dummy')]:\n",
    "    for subject_id in d.index:\n",
    "        xy = [d.loc[subject_id, left]], [d.loc[subject_id, right]]\n",
    "        plt.plot(np.array([0, 1]) + shift[label], [d.loc[subject_id, left], d.loc[subject_id, right]], alpha=0.75, color=palette[subject_id])\n",
    "plt.yscale('symlog', linthresh=1e-5)\n",
    "plt.ylim(bottom=-1e-6)\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['post_abx']))\n",
    "print(sp.stats.wilcoxon(d['pre_dummy'], d['post_dummy']))\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['pre_dummy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tax_subset = idxwhere(species_taxonomy.taxonomy_string.str.startswith('d__Bacteria;p__Firmicutes_A;c__Clostridia;o__Lachnospirales;f__Lachnospiraceae;g__Agathobacter;s__Agathobacter faecis'))\n",
    "_func = lambda ii: (species_rabund.loc[ii, _tax_subset]).sum(1).values\n",
    "d = (\n",
    "    pd.DataFrame({k: _func(perturbation_pairs[k]) for k in perturbation_pairs.columns}, index=perturbation_pairs.index)\n",
    "    .rename_axis(columns='sample_type')\n",
    "\n",
    ")\n",
    "palette = construct_ordered_palette(perturbation_pairs.index, cm='tab20')\n",
    "shift = {'abx': 0, 'dummy': 1.25}\n",
    "\n",
    "for label, left, right in [('abx', 'pre_abx', 'post_abx'), ('dummy', 'pre_dummy', 'post_dummy')]:\n",
    "    for subject_id in d.index:\n",
    "        xy = [d.loc[subject_id, left]], [d.loc[subject_id, right]]\n",
    "        plt.plot(np.array([0, 1]) + shift[label], [d.loc[subject_id, left], d.loc[subject_id, right]], alpha=0.75, color=palette[subject_id])\n",
    "plt.yscale('symlog', linthresh=1e-5)\n",
    "plt.ylim(bottom=-1e-6)\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['post_abx']))\n",
    "print(sp.stats.wilcoxon(d['pre_dummy'], d['post_dummy']))\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['pre_dummy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tax_subset = idxwhere(species_taxonomy.taxonomy_string.str.startswith('d__Bacteria;p__Firmicutes_A;c__Clostridia;o__Lachnospirales;f__Lachnospiraceae;g__Agathobacter;s__Agathobacter rectalis'))\n",
    "_func = lambda ii: (species_rabund.loc[ii, _tax_subset]).sum(1).values\n",
    "d = (\n",
    "    pd.DataFrame({k: _func(perturbation_pairs[k]) for k in perturbation_pairs.columns}, index=perturbation_pairs.index)\n",
    "    .rename_axis(columns='sample_type')\n",
    "\n",
    ")\n",
    "palette = construct_ordered_palette(perturbation_pairs.index, cm='tab20')\n",
    "shift = {'abx': 0, 'dummy': 1.25}\n",
    "\n",
    "for label, left, right in [('abx', 'pre_abx', 'post_abx'), ('dummy', 'pre_dummy', 'post_dummy')]:\n",
    "    for subject_id in d.index:\n",
    "        xy = [d.loc[subject_id, left]], [d.loc[subject_id, right]]\n",
    "        plt.plot(np.array([0, 1]) + shift[label], [d.loc[subject_id, left], d.loc[subject_id, right]], alpha=0.75, color=palette[subject_id])\n",
    "plt.yscale('symlog', linthresh=1e-5)\n",
    "plt.ylim(bottom=-1e-6)\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['post_abx']))\n",
    "print(sp.stats.wilcoxon(d['pre_dummy'], d['post_dummy']))\n",
    "print(sp.stats.wilcoxon(d['pre_abx'], d['pre_dummy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = (\n",
    "    pd.DataFrame(dict(\n",
    "        has_mgen=has_mgen_matrix,\n",
    "        library_id_list=mgen_id_list_matrix,\n",
    "        status_antibiotics=abx_status_matrix.astype(bool)\n",
    "    ))\n",
    "    .reset_index()\n",
    "    .assign(subject_week_id=lambda x: x.subject_id + '_' + x.week_number.astype(int).astype(str))\n",
    "    .set_index('subject_week_id')\n",
    "    )\n",
    "\n",
    "def _find_antibiotic_comparison_pairs(data):\n",
    "    d0 = data.sort_values(['subject_id', 'week_number']).copy()\n",
    "    d0['has_mgen'] = d0['has_mgen'].astype(bool)\n",
    "    d1 = (\n",
    "        d0.assign(\n",
    "            maybe_control=lambda x: ~(x.status_antibiotics),  # No abx this visit\n",
    "            maybe_abx=lambda x: (x.status_antibiotics),  # Abx this visit\n",
    "            maybe_dummy=lambda x: ~(x.status_antibiotics),  # No abx this visit\n",
    "        )\n",
    "        [lambda x: x.has_mgen]\n",
    "        .assign(\n",
    "            last_mgen_maybe_control=lambda x: x.maybe_control.shift(1),\n",
    "            next_mgen_maybe_abx=lambda x: x.maybe_abx.shift(-1),\n",
    "            next_mgen_maybe_dummy=lambda x: x.maybe_dummy.shift(-1),\n",
    "            time_delta_last_mgen=lambda x: x.week_number - x.week_number.shift(1),\n",
    "            time_delta_next_mgen=lambda x: x.week_number.shift(-1) - x.week_number,\n",
    "            next_subject_week_id=lambda x: x.index.to_series().shift(-1),\n",
    "        )\n",
    "    )\n",
    "    out = []\n",
    "    for pair_i, (this_subject_week_id, d2) in enumerate(d1[lambda x: x.maybe_control & x.next_mgen_maybe_abx & (x.time_delta_next_mgen <= 4.0)].iterrows()):\n",
    "        out.append(['abx', pair_i, d2.time_delta_next_mgen, this_subject_week_id, d2.next_subject_week_id])\n",
    "    for pair_i, (this_subject_week_id, d2) in enumerate(d1[lambda x: x.maybe_control & x.next_mgen_maybe_dummy & (x.time_delta_next_mgen <= 4.0)].iterrows()):\n",
    "        out.append(['dummy', pair_i, d2.time_delta_next_mgen, this_subject_week_id, d2.next_subject_week_id])\n",
    "    return pd.DataFrame(out, columns=['pair_type', 'pair_index', 'time_delta', 'left_subject_week_id', 'right_subject_week_id'])\n",
    "\n",
    "perturbation_pairs = (\n",
    "    d.groupby('subject_id')\n",
    "    .apply(_find_antibiotic_comparison_pairs)\n",
    "    .dropna()\n",
    "    .reset_index()\n",
    "    .drop(columns=['level_1'])\n",
    "    .set_index('left_subject_week_id', drop=False)\n",
    "    .rename_axis(index='subject_week_id')\n",
    ")\n",
    "perturbation_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tax = idxwhere(strain_taxonomy.taxonomy_string.str.startswith('d__Bacteria;p__Firmicutes_A;c__Clostridia;o__Lachnospirales;f__Lachnospiraceae;g__Agathobacter;s__Agathobacter rectalis'))\n",
    "_func = lambda idx: strain_rabund.loc[idx, _tax].sum(1).values\n",
    "d0 = perturbation_pairs.assign(\n",
    "    left_value=lambda x: _func(x.left_subject_week_id),\n",
    "    right_value=lambda x: _func(x.right_subject_week_id),\n",
    ")\n",
    "    \n",
    "\n",
    "\n",
    "def _response_type(x, thresh):\n",
    "    if (x.left_value > thresh) and (x.right_value < thresh):\n",
    "        return 'decreasing'\n",
    "    elif (x.left_value > thresh) and (x.right_value > thresh):\n",
    "        return 'non_decreasing'\n",
    "    elif (x.left_value < thresh) and (x.right_value < thresh):\n",
    "        return 'unknown'\n",
    "    elif (x.left_value < thresh) and (x.right_value > thresh):\n",
    "        return 'increasing'\n",
    "    else:\n",
    "        assert False, \"This shouldn't happen\"\n",
    "        \n",
    "\n",
    "thresh = 1e-4\n",
    "d0 = d0.assign(response_type=d0.apply(_response_type, thresh=thresh, axis=1))\n",
    "    \n",
    "\n",
    "palette = construct_ordered_palette(d0.response_type, cm='cool')\n",
    "shift = {'dummy': 1.25, 'abx': 0}\n",
    "\n",
    "# decreasing_pairs = idxwhere((d0.pair_type == 'abx') & (d0.left_value > thresh) & (d0.right_value < thresh))\n",
    "# non_decreasing_pairs = idxwhere((d0.pair_type == 'abx') & (d0.left_value > thresh) & (d0.right_value > thresh))\n",
    "# unknown_pairs = idxwhere((d0.pair_type == 'abx') & (d0.left_value < thresh) & (d0.right_value < thresh))\n",
    "# increasing_pairs = idxwhere((d0.pair_type == 'abx') & (d0.left_value < thresh) & (d0.right_value > thresh))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for _, d1 in d0.iterrows():\n",
    "    ax.plot(np.array([0, 1]) + shift[d1.pair_type], [d1.left_value, d1.right_value], c=palette[d1.response_type])\n",
    "ax.set_yscale('symlog', linthresh=thresh, linscale=0.1)\n",
    "ax.axhline(thresh, lw=1, linestyle='--', color='grey')\n",
    "\n",
    "d0[lambda x: x.pair_type == 'abx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(d0[lambda x: x.pair_type == 'abx'].groupby(['subject_id', 'response_type']).apply(len).unstack('response_type', fill_value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}